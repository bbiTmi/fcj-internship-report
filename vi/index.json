[{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Quách Lam Giang\nSố điện thoại: 0899197017\nEmail: nguyenlamgiang2198@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Trí tuệ nhân tạo\nLớp:\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 09/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Tạo Lambda Functions","tags":[],"description":"","content":"Bước 1: Tạo IAM Role cho Lambda Vào IAM Console → Roles → Create role\nTrusted entity type:\nAWS service Use case: Lambda Thêm permissions:\nAWSLambdaVPCAccessExecutionRole AWSLambdaBasicExecutionRole Role details:\nRole name: daivietblood-lambda-role Description: IAM role for DaiVietBlood Lambda functions Click Create role\nBước 2: Tạo Lambda Layer cho Dependencies Tạo folder cho dependencies: mkdir -p nodejs cd nodejs npm init -y npm install mysql2 Tạo file zip: cd .. zip -r mysql2-layer.zip nodejs Vào Lambda Console → Layers → Create layer\nCấu hình:\nName: mysql2-layer Upload: Chọn mysql2-layer.zip Compatible runtimes: Node.js 18.x, Node.js 20.x Click Create\nBước 3: Tạo Lambda Function - Get Users Vào Lambda Console → Functions → Create function\nBasic information:\nFunction name: daivietblood-get-users Runtime: Node.js 20.x Architecture: x86_64 Execution role: Use existing role → daivietblood-lambda-role Click Create function\nThêm Layer:\nCuộn xuống Layers → Add a layer Custom layers → Chọn mysql2-layer Click Add Cấu hình VPC:\nVào Configuration → VPC → Edit VPC: daivietblood-vpc Subnets: Chọn cả hai Private Subnets Security groups: daivietblood-lambda-sg Click Save Thêm Environment Variables:\nVào Configuration → Environment variables → Edit Thêm: DB_HOST = daivietblood-db.xxxx.ap-southeast-1.rds.amazonaws.com DB_PORT = 3306 DB_NAME = daivietblood DB_USER = admin DB_PASSWORD = YourSecurePassword123! Click Save Thêm code trong tab Code:\nconst mysql = require(\u0026#39;mysql2/promise\u0026#39;); let connection; const getConnection = async () =\u0026gt; { if (!connection) { connection = await mysql.createConnection({ host: process.env.DB_HOST, port: process.env.DB_PORT, user: process.env.DB_USER, password: process.env.DB_PASSWORD, database: process.env.DB_NAME }); } return connection; }; exports.handler = async (event) =\u0026gt; { try { const conn = await getConnection(); const [rows] = await conn.execute(\u0026#39;SELECT * FROM users\u0026#39;); return { statusCode: 200, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify(rows) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: \u0026#39;Internal server error\u0026#39; }) }; } }; Click Deploy Bước 4: Tạo Lambda Function - Create User Tạo function mới: daivietblood-create-user Cấu hình giống như trên (VPC, Layer, Environment Variables) Thêm code: const mysql = require(\u0026#39;mysql2/promise\u0026#39;); let connection; const getConnection = async () =\u0026gt; { if (!connection) { connection = await mysql.createConnection({ host: process.env.DB_HOST, port: process.env.DB_PORT, user: process.env.DB_USER, password: process.env.DB_PASSWORD, database: process.env.DB_NAME }); } return connection; }; exports.handler = async (event) =\u0026gt; { try { const body = JSON.parse(event.body); const { email, name, blood_type, phone } = body; if (!email || !name || !blood_type) { return { statusCode: 400, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: \u0026#39;Missing required fields\u0026#39; }) }; } const conn = await getConnection(); const [result] = await conn.execute( \u0026#39;INSERT INTO users (email, name, blood_type, phone) VALUES (?, ?, ?, ?)\u0026#39;, [email, name, blood_type, phone || null] ); return { statusCode: 201, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ id: result.insertId, email, name, blood_type, phone }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); if (error.code === \u0026#39;ER_DUP_ENTRY\u0026#39;) { return { statusCode: 409, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: \u0026#39;Email already exists\u0026#39; }) }; } return { statusCode: 500, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: \u0026#39;Internal server error\u0026#39; }) }; } }; Bước 5: Tạo Lambda Function - Emergency Requests Tạo function: daivietblood-emergency-requests Cấu hình giống như trên Thêm code: const mysql = require(\u0026#39;mysql2/promise\u0026#39;); let connection; const getConnection = async () =\u0026gt; { if (!connection) { connection = await mysql.createConnection({ host: process.env.DB_HOST, port: process.env.DB_PORT, user: process.env.DB_USER, password: process.env.DB_PASSWORD, database: process.env.DB_NAME }); } return connection; }; exports.handler = async (event) =\u0026gt; { const conn = await getConnection(); const method = event.httpMethod; try { if (method === \u0026#39;GET\u0026#39;) { const [rows] = await conn.execute( \u0026#39;SELECT * FROM emergency_requests WHERE status = \u0026#34;open\u0026#34; ORDER BY urgency DESC, created_at DESC\u0026#39; ); return { statusCode: 200, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify(rows) }; } if (method === \u0026#39;POST\u0026#39;) { const body = JSON.parse(event.body); const { requester_name, blood_type, units_needed, hospital, urgency } = body; const [result] = await conn.execute( \u0026#39;INSERT INTO emergency_requests (requester_name, blood_type, units_needed, hospital, urgency) VALUES (?, ?, ?, ?, ?)\u0026#39;, [requester_name, blood_type, units_needed, hospital, urgency || \u0026#39;normal\u0026#39;] ); return { statusCode: 201, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ id: result.insertId, message: \u0026#39;Emergency request created\u0026#39; }) }; } return { statusCode: 405, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: \u0026#39;Method not allowed\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: \u0026#39;Internal server error\u0026#39; }) }; } }; Checklist xác minh IAM Role đã tạo với VPC và Basic execution permissions Lambda Layer đã tạo với mysql2 package Lambda functions đã tạo và deploy: daivietblood-get-users daivietblood-create-user daivietblood-emergency-requests Tất cả functions đã cấu hình VPC (Private Subnets) Environment variables đã thiết lập đúng Functions đã deploy thành công "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo VPC","tags":[],"description":"","content":"Bước 1: Tạo VPC Vào VPC Console → Your VPCs → Create VPC\nCấu hình VPC:\nResources to create: VPC and more Name tag auto-generation: daivietblood IPv4 CIDR block: 10.0.0.0/16 IPv6 CIDR block: No IPv6 CIDR block Tenancy: Default Cấu hình Subnets:\nNumber of Availability Zones: 2 Number of public subnets: 2 Number of private subnets: 2 Customize subnets CIDR blocks: Public subnet CIDR block in ap-southeast-1a: 10.0.1.0/24 Public subnet CIDR block in ap-southeast-1b: 10.0.2.0/24 Private subnet CIDR block in ap-southeast-1a: 10.0.3.0/24 Private subnet CIDR block in ap-southeast-1b: 10.0.4.0/24 Cấu hình NAT Gateway:\nNAT gateways: In 1 AZ Cấu hình VPC Endpoints:\nVPC endpoints: None (sẽ tạo sau nếu cần) Click Create VPC\nℹ️ Việc tạo VPC mất 2-3 phút. Đợi đến khi status hiển thị \u0026ldquo;Available\u0026rdquo;.\nBước 2: Xác minh tài nguyên VPC Sau khi tạo, xác minh các tài nguyên sau đã được tạo:\nTài nguyên Tên Chi tiết VPC daivietblood-vpc 10.0.0.0/16 Public Subnet 1 daivietblood-subnet-public1-ap-southeast-1a 10.0.1.0/24 Public Subnet 2 daivietblood-subnet-public2-ap-southeast-1b 10.0.2.0/24 Private Subnet 1 daivietblood-subnet-private1-ap-southeast-1a 10.0.3.0/24 Private Subnet 2 daivietblood-subnet-private2-ap-southeast-1b 10.0.4.0/24 Internet Gateway daivietblood-igw Attached to VPC NAT Gateway daivietblood-nat-public1-ap-southeast-1a Trong Public Subnet 1 Route Table (Public) daivietblood-rtb-public Routes đến IGW Route Table (Private) daivietblood-rtb-private1-ap-southeast-1a Routes đến NAT Bước 3: Tạo Security Groups 3.1. Security Group cho Lambda\nVào VPC Console → Security Groups → Create security group\nCấu hình:\nSecurity group name: daivietblood-lambda-sg Description: Security group for Lambda functions VPC: Chọn daivietblood-vpc Inbound rules: (Để trống - Lambda khởi tạo kết nối)\nOutbound rules:\nType Protocol Port Destination Description All traffic All All 0.0.0.0/0 Allow all outbound Click Create security group\n3.2. Security Group cho RDS\nVào VPC Console → Security Groups → Create security group\nCấu hình:\nSecurity group name: daivietblood-rds-sg Description: Security group for RDS MySQL VPC: Chọn daivietblood-vpc Inbound rules:\nType Protocol Port Source Description MySQL/Aurora TCP 3306 daivietblood-lambda-sg Allow Lambda access Outbound rules:\nType Protocol Port Destination Description All traffic All All 0.0.0.0/0 Allow all outbound Click Create security group\n⚠️ Thực hành bảo mật tốt nhất: Chỉ cho phép truy cập từ Lambda Security Group đến RDS. Không bao giờ mở port 3306 cho 0.0.0.0/0.\nBước 4: Tạo DB Subnet Group Vào RDS Console → Subnet groups → Create DB subnet group\nCấu hình:\nName: daivietblood-db-subnet-group Description: Subnet group for DaiVietBlood RDS VPC: Chọn daivietblood-vpc Thêm subnets:\nAvailability Zones: Chọn ap-southeast-1a và ap-southeast-1b Subnets: Chọn cả hai Private Subnets (10.0.3.0/24 và 10.0.4.0/24) Click Create\nChecklist xác minh VPC đã tạo với CIDR 10.0.0.0/16 2 Public Subnets đã tạo 2 Private Subnets đã tạo Internet Gateway đã gắn vào VPC NAT Gateway đã tạo trong Public Subnet Route tables đã cấu hình đúng Lambda Security Group đã tạo RDS Security Group đã tạo với inbound rule từ Lambda SG DB Subnet Group đã tạo với Private Subnets "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan Workshop","tags":[],"description":"","content":"Kiến trúc Hệ thống Hệ thống DaiVietBlood sử dụng kiến trúc Serverless-First trên AWS Cloud, ưu tiên khả năng mở rộng, bảo mật và tối ưu vận hành.\nCác thành phần Kiến trúc 1. Hạ tầng Mạng (VPC)\nThành phần Mô tả VPC Virtual Private Cloud với CIDR 10.0.0.0/16 Public Subnet Chứa NAT Gateway, cho phép truy cập Internet Private Subnet Chứa Lambda, RDS - cô lập khỏi Internet NAT Gateway Cho phép tài nguyên Private Subnet truy cập Internet Internet Gateway Cho phép Public Subnet giao tiếp với Internet 2. Tầng Ứng dụng \u0026amp; Dữ liệu\nDịch vụ Vai trò AWS Lambda Xử lý logic nghiệp vụ (CRUD operations, yêu cầu cấp cứu) API Gateway Tiếp nhận HTTP requests, điều hướng đến Lambda Amazon RDS Cơ sở dữ liệu MySQL lưu trữ thông tin người dùng, kho máu Amazon S3 Lưu trữ file tĩnh (hình ảnh, tài liệu) 3. Frontend \u0026amp; Phân phối\nDịch vụ Vai trò AWS Amplify Host ứng dụng React CloudFront CDN phân phối nội dung toàn cầu với độ trễ thấp 4. DevOps \u0026amp; Giám sát\nDịch vụ Vai trò CodePipeline Tự động hóa quy trình CI/CD CodeBuild Build và test mã nguồn CloudWatch Thu thập logs, metrics, thiết lập alarms Luồng Dữ liệu User Request → CloudFront → Amplify (Frontend) ↓ API Gateway ↓ AWS Lambda (Private Subnet) ↓ Amazon RDS (Private Subnet) Mô hình Bảo mật Cô lập Mạng: RDS và Lambda nằm trong Private Subnet, không truy cập trực tiếp Internet IAM Roles: Mỗi service có quyền tối thiểu cần thiết (Least Privilege) Mã hóa Dữ liệu: At-rest (RDS, S3) và In-transit (HTTPS) Security Groups: Kiểm soát traffic inbound/outbound cho từng tài nguyên Mục tiêu Workshop Sau khi hoàn thành workshop này, bạn sẽ có thể:\n✅ Tạo VPC với phân đoạn mạng hợp lý ✅ Triển khai RDS MySQL trong Private Subnet ✅ Xây dựng Lambda functions và expose qua API Gateway ✅ Cấu hình S3 và CloudFront cho nội dung tĩnh ✅ Deploy ứng dụng React với Amplify ✅ Thiết lập CI/CD pipeline ✅ Giám sát với CloudWatch "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Xây dựng hệ thống xác minh vị trí địa lý cho iGaming và cá cược thể thao trên AWS Xác minh vị trí địa lý trong cá cược thể thao và iGaming phục vụ hai mục đích chính: tuân thủ quy định và phòng chống gian lận. Các nhà vận hành cá cược thể thao trực tuyến và iGaming cần đảm bảo rằng chỉ người chơi từ một số khu vực nhất định trên thế giới mới có thể xem nội dung do các hạn chế về cung cấp giấy phép trên thị trường. Hoặc các quy định về trò chơi có thể yêu cầu quyền truy cập bị giới hạn trong phạm vi pháp lý cho phép trong khi chặn lưu lượng trái phép tại biên giới địa lý.\nTại Hoa Kỳ, Federal Wire Act, đạo luật cấm cá cược thể thao xuyên bang, bắt đầu với đoạn văn sau:\nBất kỳ ai tham gia vào hoạt động kinh doanh cá cược hoặc cá cược mà cố ý sử dụng một hệ thống truyền thông điện tử để truyền tải trong phạm vi thương mại liên bang hoặc quốc tế các kèo cược hoặc hỗ trợ thông tin trong việc đặt cược vào bất kỳ sự kiện hoặc cuộc thi thể thao nào, hoặc để truyền tải thông tin điện tử cho phép người nhận nhận được tiền hoặc tín dụng từ kết quả của cá cược, hoặc thông tin hỗ trợ việc đặt cược, thì sẽ bị phạt tiền theo quy định tại điều luật này hoặc bị phạt tù không quá hai năm, hoặc cả hai hình phạt.\nIGT và Xổ số bang New Hampshire đã thắng kiện Bộ Tư pháp Hoa Kỳ về việc không áp dụng đạo luật Wire Act cho iGaming và vận hành xổ số. Tuy nhiên, một số bang vẫn yêu cầu người chơi và hạ tầng kinh doanh cá cược phải được đặt trong cùng một bang. Trong các bang này, nhà vận hành phải có cơ chế phát hiện VPN, phần mềm, ảo hóa và các phương pháp khác có thể được sử dụng để lách việc xác định vị trí của người chơi. Thông thường điều này có nghĩa là một SDK phải được tích hợp vào ứng dụng hoặc một phần mềm khác (sidecar) chạy song song.\nNgoài việc cho phép nhà điều hành tuân thủ quy định, kiểm soát truy cập theo vị trí địa lý còn mang lại lợi ích kinh doanh. Chặn lưu lượng ngay tại biên giúp giảm chi phí hạ tầng bằng cách loại bỏ truy cập trái phép trước khi nó đến hệ thống lõi. Các kiểm soát này cũng có thể ngăn chặn gian lận, ví dụ, cái gọi là proxy betting là nơi một người chơi trong khu vực được phép đặt cược thay cho nhiều người bên ngoài khu vực.\nLựa chọn công nghệ xác minh vị trí địa lý phụ thuộc vào trường hợp sử dụng cụ thể. Ở Hoa Kỳ, Brazil và một số khu vực khác, các nhà vận hành sử dụng hệ thống xác minh vị trí địa lý đã được cấp phép và kiểm định tuân thủ, với SDK truy cập trực tiếp vào hệ điều hành di động để đáp ứng yêu cầu chống giả mạo. Tuy nhiên, cũng có những giải pháp thay thế phù hợp cho nhà cung cấp nội dung hoặc nhà vận hành ở các khu vực khác.\nCác phương pháp này có thể được sử dụng riêng lẻ hoặc kết hợp để tạo ra giải pháp phù hợp, tùy vào yêu cầu tuân thủ và kinh doanh. Hãy khám phá năm phương pháp để xây dựng và triển khai xác minh vị trí địa lý bằng Amazon Web Services (AWS):\nGeolocation blocking sử dụng Amazon Route 53 Khả năng định tuyến vị trí địa lý (Geolocation Routing) của Amazon Route 53 có thể giới hạn quyền truy cập nội dung theo quốc gia, châu lục hoặc bang của Hoa Kỳ ngay tại lớp máy chủ hệ thống tên miền (DNS server). Cách tiếp cận dựa trên DNS này xử lý quyết định về vị trí trước khi lưu lượng truy cập đến hạ tầng của bạn, giúp giảm tải không cần thiết và chi phí liên quan. Một lợi ích chính của giải pháp này là không yêu cầu chỉnh sửa mã nguồn trên server hoặc client hiện có. Việc triển khai sử dụng DNS records với các chính sách định tuyến theo vị trí địa lý, từ đó xác định vị trí của người dùng và phản hồi dựa trên các quy tắc đã được cấu hình cho khu vực địa lý đó. Dưới đây là ví dụ về chính sách định tuyến lưu lượng theo vị trí địa lý trong Route 53:\n{ \u0026#34;RuleType\u0026#34;: \u0026#34;geo\u0026#34;, \u0026#34;Locations\u0026#34;: [ {\u0026#34;EvaluateTargetHealth\u0026#34;: true, \u0026#34;Country\u0026#34;: \u0026#34;SE\u0026#34;, \u0026#34;EndpointReference\u0026#34;: ENDPOINT_IF_TRAFFIC_ORINGINATES_FROM_SWEDEN }, { \u0026#34;Country\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;IsDefault\u0026#34;: true, \u0026#34;EvaluateTargetHealth\u0026#34;: true, \u0026#34;EndpointReference\u0026#34;: ENDPOINT_FOR_ALL_OTHER_TRAFFIC } ] } Ví dụ về chính sách định tuyến lưu lượng đến các endpoint dựa trên việc quốc gia gốc có phải là Thụy Điển hay không. Trong ví dụ này, lưu lượng bắt nguồn từ Thụy Điển sẽ được gửi đến bộ cân bằng tải, trong khi lưu lượng đến từ các khu vực khác sẽ được chuyển hướng đến một trang lỗi được hosted trên Amazon CloudFront. Định tuyến vị trí địa lý Route 53 tích hợp trực tiếp với các dịch vụ AWS khác và bao gồm cả các fallback rules cho những vị trí không khớp.\nGiải pháp định tuyến theo vị trí dựa trên DNS có một số hạn chế. Giải pháp này phụ thuộc vào độ chính xác của việc ánh xạ địa chỉ IP sang vị trí địa lý, vốn có thể bị qua mặt bởi các VPN hoặc proxy servers. Các phản hồi DNS có thể được bộ phân giải trung gian lưu trong bộ nhớ đệm, điều này có thể cho phép người dùng vẫn duy trì quyền truy cập từ một vị trí đã bị chặn sau khi họ di chuyển. Ngoài ra, giải pháp này không thể phát hiện việc can thiệp thiết bị, giả mạo vị trí, hoặc ngăn chặn hành vi cá cược thông qua proxy betting. Giải pháp này cũng chưa được phê duyệt để sử dụng trong môi trường cá cược trực tuyến được quản lý tại Mỹ, do không đáp ứng đầy đủ yêu cầu tuân thủ..\nAmazon Location Service với JavaScript Khách hàng có thể sử dụng Amazon Location Service kết hợp với JavaScript phía client để xây dựng khả năng xác định vị trí địa lý trực tiếp bên trong bất kỳ ứng dụng nào dùng JavaScript (web apps, React Native, Swift, v.v.). Phương pháp này thu thập tọa độ GPS trực tiếp từ thiết bị của người dùng, có thể cung cấp độ chính xác cao hơn so với các phương pháp dựa trên IP. Các lập trình viên phải chỉnh sửa ứng dụng của họ để thêm mã yêu cầu vị trí, tích hợp AWS SDK cho JavaScript (version 3), và tạo các API endpoints cho việc xác minh vị trí. Dưới đây là một ví dụ triển khai JavaScript cơ bản với xử lý lỗi:\n// use API Key id for credentials const authHelper = await withAPIKey(\u0026#34;api-key-id\u0026#34;); // Initialize the Location client const locationClient = new LocationClient({ region: \u0026#34;us-east-1\u0026#34;, ...authHelper.getLocationClientConfig() }); async function updateDeviceLocation() { try { // Get current position from browser const position = await new Promise((resolve, reject) =\u0026gt; { navigator.geolocation.getCurrentPosition(resolve, reject, { enableHighAccuracy: true, timeout: 10000 }); }); // Prepare the update command const command = new BatchUpdateDevicePositionCommand({ TrackerName: \u0026#34;MyDeviceTracker\u0026#34;, Updates: [{ DeviceId: \u0026#34;mobile-device-123\u0026#34;, Position: [position.coords.longitude, position.coords.latitude], SampleTime: new Date() }] }); // Send location update to Amazon Location Service const response = await locationClient.send(command); console.log(\u0026#34;Location updated successfully:\u0026#34;, response); } catch (error) { console.error(\u0026#34;Failed to update location:\u0026#34;, error); } } Amazon Location Service cung cấp một trình hỗ trợ xác thực bằng JavaScript* *(JavaScript authentication helper) để đơn giản hóa quá trình xác thực khi thực hiện API call. Bằng cách này bạn có thể tránh việc hardcode thông tin xác thực trong JavaScript. Bạn có thể sử dụng Amazon Cognito hoặc API keys làm phương thức xác thực. Giải pháp này yêu cầu có sự tương tác của người dùng. Trình duyệt sẽ hiển thị một thông báo yêu cầu quyền truy cập dịch vụ vị trí. Khi được chấp thuận, đoạn code sẽ lấy tọa độ GPS và phát ra các sự kiện (events) khi người dùng vượt qua ranh giới địa lý đã định..\nNếu sử dụng ForecastGeofenceEvents API call, Amazon Location Service có thể xác minh dựa trên các biên giới địa lý. Đối với triển khai Android WebView, lập trình viên phải bật JavaScript trong cài đặt WebView bằng cách yêu cầu quyền WKWebView trong app manifest. Ngoài ra, họ cần triển khai một permission ACCESS_FINE_LOCATION tùy chỉnh để xử lý các yêu cầu quyền truy cập vị trí. Các ứng dụng Android cũng yêu cầu một bộ nhớ đệm để lưu trữ quyền truy cập vị trí, được cấu hình thông qua thiết lập đường dẫn cơ sở dữ liệu định vị WebView.\nĐối với triển khai iOS WebView sử dụng WKWebView, vị trí địa lý được cho phép theo mặc định, nhưng lập trình viên phải thêm NSLocationWhenInUseUsageDescription key vào file Info.plist với một thông điệp giải thích lý do cần truy cập vị trí. Ứng dụng cũng phải yêu cầu quyền truy cập vị trí thông qua iOS location services framework.\nGiải pháp này chỉ khả thi cho các ứng dụng sử dụng JavaScript. Cách triển khai này có thể gây độ trễ do cần chờ người dùng cấp quyền và thu nhận tín hiệu GPS. Trải nghiệm người dùng có thể bị ảnh hưởng khi quyền truy cập vị trí bị từ chối hoặc tín hiệu GPS không khả dụng trong một số môi trường nhất định. Phương pháp này không thể phát hiện giả mạo vị trí hoặc can thiệp thiết bị. Mặc dù phương pháp này cung cấp dữ liệu vị trí chính xác hơn so với các giải pháp dựa trên IP, nó vẫn chưa đáp ứng được các yêu cầu nghiêm ngặt hơn trong các hoạt động gaming được quản lý, đặc biệt là khi cần phát hiện giả mạo vị trí.\nChặn hoặc cho phép qua Amazon CloudFront Giới hạn địa lý mà Amazon CloudFront cung cấp là một cơ chế kiểm soát quyền truy cập nội dung tại các điểm biên (edge locations) của AWS. Giải pháp này chặn hoặc cho phép các yêu cầu truy cập trước khi chúng đến được server gốc, từ đó giảm cả chi phí hạ tầng và rủi ro bảo mật tiềm ẩn.\nDưới đây là một ví dụ cấu hình giới hạn truy cập theo vị trí địa lý trong CloudFront được sử dụng trong Distribution Settings:\n{ \u0026#34;GeoRestriction\u0026#34;: { \u0026#34;RestrictionType\u0026#34;: \u0026#34;allowlist\u0026#34;, // Alternative: \u0026#34;blocklist\u0026#34; \u0026#34;Locations\u0026#34;: [ \u0026#34;GB\u0026#34;, // United Kingdom \u0026#34;IE\u0026#34;, // Ireland \u0026#34;MT\u0026#34; // Malta ] } } Bạn cũng có thể cấu hình CloudFront để thêm các tiêu đề vị trí vào các yêu cầu mà CloudFront nhận được từ người dùng và chuyển tiếp chúng đến ứng dụng của bạn. Bằng cách này, bạn có thể xây dựng logic ứng dụng để thực hiện các hành động khác ngoài việc chỉ cho phép hoặc từ chối quyền truy cập của người dùng. Tuy nhiên, các giới hạn địa lý của CloudFront chỉ hoạt động ở cấp độ quốc gia - không thể phân biệt giữa các tiểu bang của Hoa Kỳ hoặc các vùng lãnh thổ bên trong một quốc gia.\nĐối với các nhà vận hành trong những thị trường yêu cầu chặn truy cập theo cấp quốc gia, Amazon CloudFront mang đến một lớp phòng vệ đầu tiên với chi phí tối ưu. Tính năng giới hạn địa lý (geo-blocking) của CloudFront chỉ yêu cầu ít công sức phát triển và có thể được cấu hình trực tiếp thông qua AWS Management Console, giao diện dòng lệnh (CLI) hoặc các công cụ và dịch vụ Infrastructure as Code (IaC) mà không cần chỉnh sửa mã ứng dụng. Nhờ vậy, đây là một lựa chọn hấp dẫn cho việc triển khai nhanh các cơ chế kiểm soát truy cập theo vị trí địa lý cơ bản.\nViệc sử dụng tính năng giới hạn địa lý của Amazon CloudFront không phát sinh thêm chi phí ngoài phí sử dụng CloudFront tiêu chuẩn. Các yêu cầu bị chặn sẽ bị từ chối ngay tại điểm biên, do đó chi phí truyền dữ liệu gần như không đáng kể. Khi một yêu cầu bị chặn, CloudFront sẽ trả về mã lỗi HTTP 403, chỉ tiêu tốn vài byte dữ liệu truyền tải. Nhờ đó, chức năng geo-blocking của CloudFront đặc biệt tiết kiệm chi phí đối với các ứng dụng nhận khối lượng lớn lưu lượng truy cập từ những khu vực bị hạn chế.\nChặn các yêu cầu ngay tại các điểm biên của CloudFront thay vì để chúng đến máy chủ gốc có thể tiết kiệm đáng kể chi phí băng thông và giảm tải cho hạ tầng backend. Ngoài ra, vì các cuộc tấn công từ chối dịch vụ phân tán (DDoS) thường xuất phát từ một số khu vực địa lý nhất định, nên việc chặn truy cập ở cấp quốc gia có thể giảm thiểu mức độ phơi nhiễm của hệ thống trước các cuộc tấn công này, đồng thời giảm chi phí xử lý liên quan.\nTuy nhiên, chức năng geo-blocking của CloudFront có những hạn chế vượt ra ngoài mức độ phân giải theo quốc gia. Dịch vụ này xác định vị trí người dùng thông qua cơ chế ánh xạ địa chỉ IP để xác định vị trí người dùng, nên có thể bị qua mặt bởi VPN hoặc máy chủ proxy. CloudFront cũng phụ thuộc vào các header điều khiển bộ nhớ đệm và chiến lược làm mới dữ liệu để đảm bảo tính cập nhật của dữ liệu trong các API động - điều này có nghĩa là dữ liệu vị trí không phải lúc nào cũng được cập nhật theo thời gian thực. Ngoài ra, phương pháp này không hỗ trợ kiểm tra tính toàn vẹn của thiết bị hoặc các biện pháp chống giả mạo vị trí, do đó không phù hợp cho các nhà vận hành trong lĩnh vực iGaming hoặc cá cược thể thao với những yêu cầu nghiêm ngặt hơn về xác thực vị trí địa lý.\nAWS WAF với geo match statements AWS WAF cung cấp cơ chế kiểm soát truy cập theo vị trí địa lý thông qua các câu lệnh đối sánh địa lý, mang lại mức độ kiểm soát chi tiết hơn so với tính năng geo-blocking của CloudFront. Dịch vụ này có thể lọc lưu lượng truy cập dựa trên cả quốc gia và tiểu bang của Hoa Kỳ, giúp nó trở thành một công cụ hữu ích cho các nhà vận hành cần kiểm soát truy cập với độ chính xác theo vùng.\nDưới đây là một ví dụ về quy tắc AWS WAF với câu lệnh đối sánh địa lý:\n{ \u0026#34;Name\u0026#34;: \u0026#34;RegionalAccessControl\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;GeoMatchStatement\u0026#34;: { \u0026#34;CountryCodes\u0026#34;: [\u0026#34;SG\u0026#34;], \u0026#34;ForwardedIPConfig\u0026#34;: { \u0026#34;HeaderName\u0026#34;: \u0026#34;X-Forwarded-For\u0026#34;, \u0026#34;FallbackBehavior\u0026#34;: \u0026#34;MATCH\u0026#34; } } }, \u0026#34;Action\u0026#34;: { \u0026#34;Allow\u0026#34;: {} }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;SampledRequestsEnabled\u0026#34;: true, \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;RegionalAccessMetric\u0026#34; } } Ưu điểm nổi bật của AWS WAF geo matching là khả năng tích hợp với chỉ số giám sát của Amazon CloudWatch, cho phép giám sát chi tiết các yêu cầu bị chặn và các mẫu lưu lượng. Khả năng quan sát này giúp các nhà vận hành hiểu rõ hơn về hành vi truy cập và điều chỉnh chiến lược chặn truy cập một cách phù hợp. AWS WAF cũng hỗ trợ xử lý lưu lượng IPv6 một cách nguyên bản và có thể xử lý các yêu cầu dựa trên header X-Forwarded-For, điều này đặc biệt quan trọng đối với các ứng dụng chạy phía sau proxy server hoặc load balancer.\nTuy nhiên, tính năng đối sánh địa lý của AWS WAF không thể phát hiện các hình thức giả mạo vị trí phức tạp hoặc xác minh tính toàn vẹn của thiết bị. Mặc dù dịch vụ này có thể nhận diện và chặn lưu lượng đến từ các dịch vụ proxy hoặc điểm cuối VPN đã biết, nhưng những người dùng cố tình vẫn có thể vượt qua các cơ chế kiểm soát này.\nCác nhà cung cấp xác minh vị trí địa lý được cấp phép Có nhiều quốc gia và khu vực pháp lý đặt ra yêu cầu nghiêm ngặt đối với hệ thống xác minh vị trí địa lý (ví dụ, Hoa Kỳ và Brazil). Đối với các nhà vận hành trò chơi có quản lý, các thị trường này thường yêu cầu hệ thống xác minh vị trí có khả năng phát hiện và ngăn chặn hành vi giả mạo vị trí bằng cách xác minh tính toàn vẹn ở cấp độ thiết bị. Các nhà cung cấp dịch vụ xác minh vị trí được cấp phép như GeoComply, OpenBet, và Xpoint hiện đang cung cấp các khả năng nêu trên.\nCác giải pháp của những công ty này khác biệt một cách căn bản so với các giải pháp được mô tả trước đó trong cách tiếp cận xác minh vị trí. Thay vì chỉ dựa vào địa chỉ IP hoặc tọa độ GPS, chúng thu thập thông tin vị trí trực tiếp từ thiết bị (sử dụng phương pháp định vị tam giác Wi-Fi, tín hiệu GPS, v.v.). Các hệ thống này xác minh tính toàn vẹn của thiết bị thông qua bộ SDK chuyên biệt cho từng thiết bị, dùng để kiểm tra hệ điều hành nhằm phát hiện dấu hiệu can thiệp, sử dụng VPN hoặc phần mềm giả mạo vị trí.\nCác hệ thống quản lý hàng rào địa lý xác định xem thiết bị có nằm trong hoặc gần ranh giới của một hàng rào địa lý hay không, có thể là ranh giới giữa các tiểu bang hoặc khu vực hành chính. Việc giám sát theo thời gian thực giúp phát hiện những thay đổi vị trí đột ngột có thể cho thấy hành vi cá cược qua proxy hoặc các hoạt động gian lận khác. Việc xây dựng các hệ thống này thường đòi hỏi sự tích hợp ở nhiều cấp độ, bao gồm:\nNative SDK (iOS và Android) tích hợp cho mobile apps\nBrowser plugin hoặc sidecar application cho web apps\nTích hợp API của Amazon Location Services\nBáo cáo tuân thủ endpoints\nCác nhà cung cấp dịch vụ xác minh vị trí được cấp phép là một lựa chọn phù hợp trong các trường hợp sau:\nQuy định yêu cầu xác minh hàng rào địa lý và xác minh vị trí (chẳng hạn như US Federal Wire Act hoặc luật cá cược của Brazil)\nYêu cầu pháp lý bắt buộc phải có biện pháp chống giả mạo và xác minh tính toàn vẹn thiết bị\nNhà vận hành cần ngăn chặn proxy betting thông qua các biện pháp kiểm tra tinh vi ở cấp thiết bị\nKết luận Việc lựa chọn giải pháp xác minh vị trí địa lý phụ thuộc vào nhiều yếu tố, bao gồm yêu cầu pháp lý tại khu vực mục tiêu, hồ sơ rủi ro, và chi phí. Mặc dù nhiều nhà vận hành triển khai nhiều lớp bảo vệ, nhưng điều quan trọng là phải hiểu rõ giải pháp nào phù hợp, dựa trên những rủi ro và yêu cầu cụ thể. Nếu không cần các tiêu chuẩn nghiêm ngặt, những giải pháp ít tốn kém hơn đã được nêu ở trên vẫn có thể cung cấp khả năng xác minh vị trí địa lý hữu ích, đồng thời duy trì hiệu năng và trải nghiệm người dùng.\nLiên hệ AWS Representative để chúng tôi giúp tăng tốc doanh nghiệp của bạn.\nĐọc thêm Guidance for Building Geolocation Systems for the Betting \u0026amp; Gaming Industry on AWS Amazon Location Service launches Enhanced Location Integrity features OpenBet Delivers Geolocation Integrity for Betting and Gaming Using Solutions on AWS Winning the Cat-and-Mouse Race: Staying One Step Ahead of Streaming Geopiracy with GeoGuard and AWS Dr. Mike Reaves Dr.Mike Reaves là Kiến trúc sư Giải pháp Cấp cao (Principal Solutions Architect) trong lĩnh vực Betting \u0026amp; Gaming tại Amazon Web Services (AWS). Ông làm việc với khách hàng để xây dựng chiến lược kỹ thuật, đồng thời ứng dụng các công nghệ của AWS nhằm phát triển những giải pháp chuyên biệt phù hợp với nhu cầu của từng doanh nghiệp. Là một chuyên gia kỳ cựu trong ngành, Dr.Reaves là kiến trúc sư giải pháp được chứng nhận bởi AWS, với hơn 25 năm kinh nghiệm trong phát triển phần mềm và công nghệ thông tin. Ông nhận bằng Tiến sĩ Vật lý tại Đại học Connecticut.\nDr. Haowen You Dr.Haowen You hiện là Quản lý Kỹ thuật Phần mềm mảng Không gian Địa lý (Software Engineering Manager, Geospatial) tại Amazon Web Services (AWS). Ông phụ trách đội ngũ phát triển phần mềm cho Amazon Location Service. Với hơn 12 năm kinh nghiệm trong việc quản lý các nhóm và dự án phần mềm, Tiến sĩ You hiện đang tập trung vào các sản phẩm Trí tuệ nhân tạo ứng dụng (Applied AI) của AWS. Ông nhận bằng Tiến sĩ Kỹ thuật Hệ thống tại Đại học Virginia.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Cách thực thi AI model inference với GPUs trên Amazon EKS Auto Mode Việc suy luận mô hình AI (AI model inference) bằng GPU đang trở thành thành phần cốt lõi trong các ứng dụng hiện đại, thúc đẩy các hệ thống gợi ý theo thời gian thực, trợ lý thông minh, tạo nội dung tự động, và các tính năng AI yêu cầu độ trễ thấp khác.Kubernetes đã trở thành nền tảng điều phối (orchestrator) được ưa chuộng để chạy các tác vụ suy luận, và các tổ chức muốn tận dụng những khả năng này trong khi vẫn tập trung hoàn toàn vào duy trì tốc độ đổi mới và thời gian ra mắt sản phẩm nhanh. Tuy nhiên thách thức đặt ra là: trong khi nhóm kỹ thuật nhận thấy giá trị của Kubernetes trong khả năng mở rộng linh hoạt và quản lý tài nguyên hiệu quả, họ thường bị chậm lại do phải học các Kubernetes concepts, quản lý cấu hình cụm (cluster configurations) và xử lý các bản cập nhật bảo mật. Điều này khiến họ phân tán khỏi mục tiêu chính: triển khai và tối ưu hóa mô hình AI. Đó chính là lý do Amazon Elastic Kubernetes Service (Amazon EKS) Auto Mode ra đời. EKS Auto Mode tự động hóa việc tạo node, quản lý các chức năng cốt lõi, và xử lý nâng cấp và vá bảo mật, giúp bạn có thể chạy các tác vụ suy luận AI mà không phải gánh chịu chi phí vận hành phức tạp.\nTrong bài viết này, chúng tôi sẽ hướng dẫn bạn triển khai nhanh chóng các tác vụ suy luận trên EKS Auto Mode. Chúng tôi cũng sẽ giới thiệu các tính năng quan trọng giúp đơn giản hóa việc quản lý GPU, trình bày các phương pháp triển khai mô hình tối ưu, và minh họa bằng một ví dụ thực tế thông qua việc triển khai các mô hình mã nguồn mở của OpenAI thông qua vLLM. Dù bạn đang xây dựng một nền tảng AI/machine learning (ML) mới hay tối ưu hóa quy trình hiện có, những mẫu triển khai này sẽ giúp bạn tăng tốc quá trình phát triển trong khi vẫn duy trì hiệu quả vận hành.\nTính năng chính khiến EKS Auto Mode lý tưởng cho AI/ML workloads Trong phần này, chúng ta sẽ tìm hiểu chi tiết hơn về các tính năng chuyên biệt cho GPU được cấu hình sẵn và sẵn sàng sử dụng trong EKS Auto Mode clusters. Những khả năng này cũng có sẵn trong môi trường Amazon EKS tự quản lý, nhưng thường cần phải thiết lập và tinh chỉnh. Tuy nhiên, với EKS Auto Mode các tính năng này được kích hoạt và cấu hình sẵn ngay từ đầu.\nTự động mở rộng linh hoạt với Karpenter: EKS Auto Mode bao gồm một phiên bản được quản lý của Karpenter cung cấp một công cụ mã nguồn mở tương thích với Amazon Elastic Compute Cloud (Amazon EC2) có kích thước phù hợp, bao gồm cả các tùy chọn tăng tốc bằng GPU, dựa trên yêu cầu của pod. Giải pháp này hỗ trợ cơ chế mở rộng tức thời và cho phép bạn tùy chỉnh hành vi cấp phát tài nguyên để tối ưu theo chi phí, hiệu năng hoặc vị trí triển khai của instance. EKS Auto Mode hỗ trợ sẵn các loại và kích thước instance được định nghĩa trước, đồng thời cung cấp các nhãn và thuộc tính hạn chế (taints) để kiểm soát lịch trình triển khai một cách chính xác.\nTự động xử lý sự cố GPU: EKS Auto Mode bao gồm Node Monitoring Agent (NMA) và Node Auto Repair, cho phép phát hiện lỗi GPU và tự động khởi động quá trình khôi phục sau 10 phút kể từ khi phát hiện sự cố. Hệ thống sửa chữa sẽ cô lập node bị ảnh hưởng và thực hiện khởi động lại hoặc thay thế node đó, trong khi vẫn tuân thủ Pod Disruption Budgets. Các công cụ giám sát GPU, như DCGM-Exporter cho NVIDIA hoặc Neuron Monitor cho Amazon Web Services (AWS) Inferentia và AWS Trainium, được cài đặt sẵn và tích hợp với NMA giúp giám sát tình trạng phần cứng ở cấp độ thiết bị.\nAmazon EKS-optimized AMIs cho instances tăng tốc (accelerated instances): EKS Auto Mode cho phép bạn tạo một Karpenter NodePool sử dụng GPU instance. Hơn nữa, khi workload yêu cầu GPU, hệ thống sẽ tự động khởi tạo Amazon Machine Image (AMI) Bottlerocket Accelerated - mà không cần cấu hình thủ công AMI IDs, mẫu khởi chạy (launch templates), hoặc software components. Các AMIs này được cài đặt sẵn driver cần thiết, runtimes, và plugins, dù bạn đang sử dụng GPU của NVIDIA hay bộ tăng tốc AWS Inferentia và Trainium, nhờ vậy AI workloads của bạn sẵn sàng chạy ngay mặc định.\nTổng hợp lại, các tính năng này loại bỏ phần lớn công việc phức tạp trong việc cấu hình và vận hành hạ tầng GPU, giúp các nhóm kỹ thuật tập trung vào việc xây dựng, mở rộng và triển khai các tác vụ AI/ML mà không cần phải trở thành chuyên gia Kubernetes.\nHướng dẫn thực hành Trong phần này, bạn sẽ thực hành triển khai một mô hình LLM mã nguồn mở trên EKS Auto Mode có hỗ trợ GPU. Bạn sẽ tạo cluster, cấu hình một GPU NodePool, triển khai mô hình, và gửi một truy vấn thử nghiệm (test prompt), tất cả chỉ với cấu hình đơn giản.\nYêu cầu Để bắt đầu, hãy đảm bảo rằng bạn đã tải và cài đặt cấu hình sau:\nAWS Command Line Interface (AWS CLI (v2.27.11 hoặc phiên bản gần nhất)\nkubectl\neksctl (v0.195.0 hoặc phiên bản gần nhất)\njq\nCài đặt biến môi trường Cấu hình các biến môi trường, thay thế các giá trị mẫu bằng thông tin của bạn:\nexport CLUSTER_NAME=automode-gpu-blog-cluster export AWS_REGION=us-west-2 Cài đặt EKS Auto Mode cluster và chạy model Bước 1: Tạo một EKS Auto Mode bằng eksctl\nBắt đầu tạo EKS cluster của bạn với Auto Mode có sẵn bằng cách chạy dòng dưới trong command:\neksctl create cluster --name=$CLUSTER_NAME --region=$AWS_REGION --enable-auto-mode Quá trình này có thể mất vài phút để hoàn thánh. Sau khi hoàn tất, eksctl tự động cập nhật kubeconfig và chuyển sang cluster vừa được tạo. Để xác minh rằng cluster đang hoạt động, sử dụng lệnh sau:\nkubectl get pods --all-namespaces Ví dụ về output:\nNAMESPACE NAME READY STATUS RESTARTS AGE kube-system metrics-server-6d67d68f67-7x4tg 1/1 Running 0 3m kube-system metrics-server-6d67d68f67-l4xv6 1/1 Running 0 3m Bạn sẽ không thấy các thành phần như VPC CNI, kube-proxy, Karpenter và CoreDNS trong danh sách pod. Trong EKS Auto Mode, AWS vận hành các thành phần này trên lớp hạ tầng được quản lý hoàn toàn, cùng với control plane của Amazon EKS.\nBước 2: Tạo một GPU NodePool với Karpenter\nTriển khai một GPU NodePool được thiết kế để chạy ML models. Áp dụng NodePool manifest:\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: karpenter.sh/v1 kind: NodePool metadata: name: gpu-node-pool spec: template: metadata: labels: type: karpenter NodeGroupType: gpu-node-pool spec: nodeClassRef: group: eks.amazonaws.com kind: NodeClass name: default taints: - key: nvidia.com/gpu value: Exists effect: NoSchedule requirements: - key: karpenter.sh/capacity-type operator: In values: [\u0026#34;spot\u0026#34;, \u0026#34;on-demand\u0026#34;] - key: eks.amazonaws.com/instance-category operator: In values: [\u0026#34;g\u0026#34;] - key: eks.amazonaws.com/instance-generation operator: Gt values: [\u0026#34;4\u0026#34;] - key: kubernetes.io/arch operator: In values: [\u0026#34;amd64\u0026#34;] limits: cpu: 100 memory: 100Gi EOF NodePool này nhắm tới các instance EC2 dùng GPU thuộc họ g với thế hệ từ 4 trở đi, chẳng hạn G5 và G6e. Những instance này này cung cấp GPU NVIDIA mạnh cùng kết nối mạng băng thông cao, nên rất phù hợp cho các workload suy luận ML đòi hỏi cao và generative AI. Taint được áp dụng đảm bảo chỉ các pod đủ điều kiện dùng GPU mới được lên lịch trên các node này, duy trì cô lập tài nguyên hiệu quả. Việc cho phép đồng thời hai loại On-Demand và Spot mang lại cho EKS Auto Mode tính linh hoạt để tối ưu chi phí trong khi vẫn đảm bảo hiệu năng.\nKiểm tra NodePool:\nkubectl get nodepools Mẫu output:\nNAME NODECLASS NODES READY AGE general-purpose default 0 True 15m gpu-node-pool default 0 True 8s system default 2 True 15m gpu-node-pool được khởi tạo với 0 node. Để kiểm tra, chạy lệnh sau:\nkubectl get nodes -o custom-columns=NAME:.metadata.name,READY:\u0026#34;status.conditions[?(@.type==\u0026#39;Ready\u0026#39;)].status\u0026#34;,OS-IMAGE:.status.nodeInfo.osImage,INSTANCE-TYPE:.metadata.labels.\u0026#39;node\\.kubernetes\\.io/instance-type\u0026#39;,LIFECYCLE:.metadata.labels.\u0026#39;karpenter\\.sh/capacity-type\u0026#39; Mẫu output:\nNAME READY OS-IMAGE INSTANCE-TYPE LIFECYCLE i-0319343e8ad4c5f14 True Bottlerocket (EKS Auto, Standard) 2025.7.18 (aws-k8s-1.32-standard) c6g.large on-demand i-0a3ff5bfd7be551e2 True Bottlerocket (EKS Auto, Standard) 2025.7.18 (aws-k8s-1.32-standard) c6g.large on-demand EKS Auto Mode khởi chạy hai c6g instances sử dụng Bottlerocket AMI không tăng tốc (non-accelerated) (aws-k8s-1.32-standard), các instance này chỉ sử dụng CPU (CPU-only) và được dùng để chạy dịch vụ metrics server.\nBước 3. Triển khai mô hình gpt-oss-20b sử dụng vLLM\nvLLM là công cụ suy luận (inference engine) mã nguồn mở hiệu năng cao được tối ưu hóa cho các mô hình ngôn ngữ lớn (LLMs). Tệp YAML triển khai container image độc lập (model-agnostic) vllm``/``vllm``-openai:``gptoss. Trong ví dụ này, ta chỉ định openai/gpt-oss-20b làm mô hình mà vLLM sẽ phục vụ.\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: gpt-oss-20b spec: replicas: 1 selector: matchLabels: app: vllm-gptoss-20b template: metadata: labels: app: vllm-gptoss-20b spec: tolerations: - key: nvidia.com/gpu operator: Exists effect: NoSchedule containers: - name: inference-server ` image: ``vllm``/``vllm``-openai:``gptoss` ports: - containerPort: 8000 resources: limits: nvidia.com/gpu: 1 command: [ \u0026#34;vllm\u0026#34;, \u0026#34;serve\u0026#34; ] args: - openai/gpt-oss-20b - --gpu-memory-utilization=0.90 - --tensor-parallel-size=1 - --max-model-len=20000 env: - name: VLLM_ATTENTION_BACKEND value: \u0026#34;TRITON_ATTN_VLLM_V1\u0026#34; - name: PORT value: \u0026#34;8000\u0026#34; volumeMounts: - mountPath: /dev/shm name: dshm volumes: - name: dshm emptyDir: medium: Memory --- apiVersion: v1 kind: Service metadata: name: gptoss-service spec: selector: app: vllm-gptoss-20b ports: - port: 8000 targetPort: 8000 type: ClusterIP EOF Triển khai này sử dụng toleration (miễn nhiễm) nvidia.com/gpu, tương ứng với taint trên GPU NodePool. Ban đầu, chưa có node GPU nào tồn tại, vì vậy pod sẽ ở trạng thái Pending. Karpenter sẽ phát hiện pod không thể được lên lịch và tự động khởi tạo một node GPU mới. Khi instance sẵn sàng, pod được lên lịch và chuyển sang trạng thái ContainerCreating, tại thời điểm đó hệ thống bắt đầu tải (pull) container image của vllm. Sau khi container image được tải và giải nén hoàn tất, container chuyển sang trạng thái Running.\nChờ đến khi pod chuyển sang trạng thái Running. Để theo dõi các sự kiện của pod, dùng lệnh sau:\nkubectl get pods -l app=vllm-gptoss-20b -w Mẫu output:\nNAME READY STATUS RESTARTS AGE gpt-oss-20b-7dc7f7658d-8xsbm 1/1 Running 0 5m Để kiểm tra pod event dùng lệnh:\nkubectl describe pod -l app=vllm-gptoss-20b Mẫu output:\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 2m33s default-scheduler 0/1 nodes are available: 1 node(s) had untolerated taint {CriticalAddonsOnly: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling. Normal Nominated 2m32s eks-auto-mode/compute Pod should schedule on: nodeclaim/gpu-node-pool-c4bb5 Normal Scheduled 95s default-scheduler Successfully assigned default/gpt-oss-20b-68b49c7b44-2r7gr to i-05a572a3bbed6669f Normal Pulling 89s kubelet Pulling image \u0026#34;public.ecr.aws/deep-learning-containers/vllm:0.11.2-gpu-py312-ec2-soci\u0026#34; Normal Pulled 1s kubelet Successfully pulled image \u0026#34;public.ecr.aws/deep-learning-containers/vllm:0.11.2-gpu-py312-ec2-soci\u0026#34; in 1m27.666s (1m27.666s including waiting). Image size: 14221606791 bytes. Normal Created 1s kubelet Created container: inference-server Normal Started 1s kubelet Started container inference-server Mất vài phút để pod chuyển sang trạng thái Running. Trong ví dụ trên, Karpenter đã khởi tạo instance và lên lịch cho pod chưa đầy một phút. Thời gian còn lại dùng để tải image vllm từ internet, có dung lượng khoảng 14 GB.\nKhi container chuyển sang trạng thái Running, trọng số của mô hình (model weights) bắt đầu được nạp vào bộ nhớ GPU, quá trình này mất vài phút để hoàn tất. Xem logs để theo dõi tiến trình:\nkubectl logs -l app=vllm-gptoss-20b -f Khi mô hình được tải xong, bạn sẽ thấy output giống như sau:\nINFO 08-22 22:26:52 [launcher.py:37] Route: /rerank, Methods: POST INFO 08-22 22:26:52 [launcher.py:37] Route: /v1/rerank, Methods: POST INFO 08-22 22:26:52 [launcher.py:37] Route: /v2/rerank, Methods: POST INFO 08-22 22:26:52 [launcher.py:37] Route: /scale_elastic_ep, Methods: POST INFO 08-22 22:26:52 [launcher.py:37] Route: /is_scaling_elastic_ep, Methods: POST INFO 08-22 22:26:52 [launcher.py:37] Route: /invocations, Methods: POST INFO 08-22 22:26:52 [launcher.py:37] Route: /metrics, Methods: GET INFO: Started server process [1] INFO: Waiting for application startup. INFO: Application startup complete. Sau khi áp dụng manifest, Karpenter đã khởi tạo một GPU instance đáp ứng các ràng buộc (constraints) được định nghĩa trong NodePool. Để xem instance nào đã được khởi tạo, chạy lệnh sau:\nkubectl get nodes -o custom-columns=NAME:.metadata.name,READY:\u0026#34;status.conditions[?(@.type==\u0026#39;Ready\u0026#39;)].status\u0026#34;,OS-IMAGE:.status.nodeInfo.osImage,INSTANCE-TYPE:.metadata.labels.\u0026#39;node\\.kubernetes\\.io/instance-type\u0026#39;,LIFECYCLE:.metadata.labels.\u0026#39;karpenter\\.sh/capacity-type\u0026#39; Mẫu output:\nNAME READY OS-IMAGE INSTANCE-TYPE LIFECYCLE i-0319343e8ad4c5f14 True Bottlerocket (EKS Auto, Standard) 2025.7.18 (aws-k8s-1.32-standard) c6g.large on-demand i-0a3ff5bfd7be551e2 True Bottlerocket (EKS Auto, Standard) 2025.7.18 (aws-k8s-1.32-standard) c6g.large on-demand i-029d33a1259f77564 True Bottlerocket (EKS Auto, Nvidia) 2025.7.25 (aws-k8s-1.32-nvidia) g6e.xlarge spot Trong trường hợp này Karpenter xác định rằng G6e xlarge spot instance là loại instance có chi phí hiệu quả và tuân thủ các ràng buộc được định nghĩa trong NodePool.\nBước 5. Kiểm tra model endpoints\nĐầu tiên, thực thi một port forward đến gptoss``-service service sử dụng kubectl:\nkubectl port-forward service/gptoss-service 8000:8000 Trong một terminal khác, gửi một test prompt bằng cách sử dụng curl:\ncurl http://localhost:8000/v1/chat/completions \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;openai/gpt-oss-20b\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What is machine learning?\u0026#34; } ], \u0026#34;temperature\u0026#34;: 0.7, \u0026#34;max_tokens\u0026#34;: 100 }\u0026#39; | jq -r \u0026#39;.choices[0].message.content\u0026#39; Mẫu output:\n**Machine learning (ML)** is a branch of computer science that gives computers the ability to learn from data, identify patterns, and make decisions or predictions without being explicitly programmed to perform each specific task. Thiết lập này cho phép bạn test và tương tác với inference server của mình mà không cần công khai nó ra bên ngoài. Để làm cho nó có thể truy cập được bởi các ứng dụng hoặc người dùng khác, bạn có thể cập nhật service type thành LoadBalancer, cho phép truy cập từ bên ngoài hoặc trong VPC của bạn. Nếu công khai service, hãy đảm bảo triển khai các kiểm soát truy cập phù hợp như authentication, authorization, và rate limiting.\nBước 5. Dọn dẹp tài nguyên\nKhi bạn đã hoàn thành các thử nghiệm của mình, bạn phải dọn dẹp các tài nguyên đã tạo để tránh phát sinh chi phí liên tục. Để xóa cluster và tất cả các tài nguyên liên quan được quản lý bởi EKS Auto Mode, hãy chạy lệnh sau:\neksctl delete cluster --name=$CLUSTER_NAME --region=$AWS_REGION Lệnh này sẽ xóa toàn bộ EKS cluster cùng với control plane, data plane nodes, NodePools, và tất cả các tài nguyên được quản lý bởi EKS Auto Mode.\nCách giảm thời gian khởi động “cold start” cho AI inference workloads Như bạn đã thấy trong phần trước, quá trình này mất vài phút để container image được tải xuống, model được lấy về, và weights được nạp vào GPU memory. Độ trễ này thường được gây ra bởi container image có kích thước lớn (trên 17GB trong trường hợp này), việc tải model từ nguồn bên ngoài, và thời gian cần thiết để nạp model vào bộ nhớ, tất cả đều làm tăng độ trễ khi pod khởi động và trong các sự kiện mở rộng. Trong môi trường sản xuất, đặc biệt khi chạy inference ở quy mô lớn, bạn phải sử dụng Kubernetes autoscaling và giảm thiểu thời gian khởi động này để đảm bảo mở rộng nhanh và phản hồi kịp thời. Trong phần này, chúng ta sẽ đi qua các kỹ thuật nhằm tối ưu hóa thời gian khởi động model và giảm độ trễ khởi động lạnh (cold start delays).\nLưu trữ vLLM container image trong Amazon ECR và sử dụng VPC endpoint: Pulling container images từ các public registries trên internet gây ra độ trễ trong quá trình pod khởi động, đặc biệt khi image có kích thước lớn hoặc băng thông mạng bị giới hạn. Để giảm chi phí xử lý này:\nLưu trữ container image của bạn trong Amazon Elastic Container Registry (Amazon ECR), một container registry được quản lý hoàn toàn khả dụng theo khu vực và được tối ưu hóa để dùng với Amazon EKS.\nCấu hình Amazon ECR VPC endpoint để các nodes pull images thông qua AWS backbone thay vì public internet.\nCác mô hình được tải sẵn (prefetch model artifacts) bằng cách sử dụng các tùy chọn của AWS Storage: Để giảm thời gian khởi động do việc tải xuống và load model từ Hugging Face gây ra, hãy lưu trữ các model artifacts trong một tùy chọn lưu trữ AWS hỗ trợ truy cập đồng thời và đọc với thông lượng cao trên nhiều nodes và AWS Availability Zones (AZs). Điều này là thiết yếu khi nhiều bản sao của inference service của bạn,có thể đang chạy trên các nodes hoặc AZs khác nhau, cần đọc cùng một model weights đồng thời. Việc sử dụng shared storage giúp tránh phải tải xuống và lưu trữ các bản sao trùng lặp của model cho mỗi pod hoặc node.\nAmazon S3 **với **Mountpoint **và **S3 Express One Zone: Express One Zone lưu trữ dữ liệu trong một AZ, mặc dù dữ liệu đó có thể được truy cập từ các AZ khác trong cùng một Region. Đây là tùy chọn lưu trữ có chi phí thấp nhất và dễ thiết lập nhất. Giải pháp này lý tưởng cho các công việc suy luận tổng quát nơi yêu cầu hiệu năng ở mức vừa phải và độ trực tiếp là yếu tố chính. Để đạt kết quả tốt nhất, hãy cấu hình một VPC endpoint nhằm đảm bảo rằng lưu lượng luôn nằm trong mạng AWS.\nAmazon Elastic File System (Amazon EFS): Là một dịch vụ đa vùng sẵn có (natively multi-AZ service), tự động sao chép dữ liệu giữa các AZs. Amazon EFS là một hệ thống chia sẻ tệp dễ sử dụng, mang lại sự cân bằng tốt giữa chi phí, độ trễ và thông lượng. Phù hợp cho các tải công việc cần truy cập mô hình ổn định từ nhiều AZs, với tính sẵn sàng cao được tích hợp sẵn.\nAmazon FSx for Lustre: Được triển khai trong một AZ duy nhất và có thể truy cập từ các AZ khác trong cùng một VPC. Dịch vụ này cung cấp tùy chọn hiệu năng cao nhất cho shared storage.Mặc dù FSx for Lustre có thể có chi phí lưu trữ cao hơn, nhưng tốc độ tải model weights của nó có thể giảm thời gian trống của GPU (GPU idle time), thường cân bằng lại chi phí đồng thời mang lại hiệu suất tải mô hình nhanh nhất.\nTách biệt model artifacts khỏi container images, lưu trữ containers của bạn trong Amazon ECR, và lựa chọn storage backend phù hợp cho models của bạn,chẳng hạn như Amazon S3 Mountpoint, Amazon EFS, hoặc Amazon FSx for Lustre cho phép bạn giảm đáng kể thời gian khởi động và cải thiện khả năng phản hồi của các tải công việc suy luận. Để khám phá thêm các chiến lược nhằm tối ưu hóa thời gian khởi động của container và model trên Amazon EKS, hãy tham khảo tài liệu AI on Amazon EKS guidance.\nKết luận Amazon EKS Auto Mode đơn giản hóa việc chạy các công việc suy luận AI sử dụng GPU bằng cách xử lý các tác vụ như khởi tạo cluster, node scaling, và cấu hình GPU thay cho bạn. Tự động mở rộng động thông qua Karpenter, AMIs được cấu hình sẵn, cùng với giám sát và khôi phục GPU tích hợp cho phép bạn triển khai model nhanh hơn - mà không cần phải cấu hình hoặc duy trì hạ tầng nền tảng.\nĐể tìm hiểu thêm về việc chạy các inference workloads trên EKS Auto Mode, dưới đây là một vài bước tiếp theo:\nTìm hiểu thêm: Truy cập EKS Auto Mode documentation để xem đầy đủ capabilities, các loại instance được hỗ trợ, và tùy chọn cấu hình. Bạn cũng có thể xem EKS Auto Mode post để giới thiệu thực hành.\nTrải nghiệm thực tế: Tham gia các buổi hội thảo ảo có giảng viên hướng dẫn thuộc chuỗi Amazon EKS series, trong đó có các session chuyên biệt về Auto Mode và AI inference.\nKhám phá các phương pháp tốt nhất: Xem Amazon EKS best practices guide for AI/ML workloads.\n**Lập kế hoạch về khả năng mở rộng và chi phí: **Nếu bạn đang chạy LLMs hoặc GPU workloads có nhu cầu cao, hãy liên hệ với AWS account team của bạn để được hướng dẫn về định giá, khuyến nghị tối ưu kích thước, và hỗ trợ lập kế hoạch. AWS gần đây đã thông báo giảm giá tới 45% cho các instance được tăng tốc bằng NVIDIA GPU, bao gồm P4d, P4de, và P5, vì vậy đây là thời điểm thích hợp để đánh giá các tùy chọn của bạn.\nCác công cụ và hướng dẫn này cho phép bạn chạy các tải công việc suy luận ở quy mô lớn với ít nỗ lực hơn và tự tin hơn.\nCác tác giả Shivam Dubey là Kiến trúc sư Giải pháp Chuyên biệt (Specialist Solutions Architect) tại Amazon Web Services (AWS), nơi anh hỗ trợ khách hàng xây dựng các giải pháp mở rộng quy mô và tích hợp Trí tuệ nhân tạo trên Amazon EKS. Anh có niềm đam mê với các công nghệ mã nguồn mở và vai trò của chúng trong kiến trúc điện toán đám mây hiện đại. Ngoài công việc, Shivam yêu thích leo núi, tham quan các công viên quốc gia và khám phá những thể loại âm nhạc mới.\nBharath Gajendran là Quản lý Tài khoản Kỹ thuật tại Amazon Web Services (AWS), nơi anh hỗ trợ khách hàng thiết kế và vận hành các khối lượng công việc có khả năng mở rộng cao, tối ưu chi phí và chịu lỗi hiệu quả bằng cách tận dụng các dịch vụ của AWS. Anh có niềm đam mê với Amazon EKS và các công nghệ mã nguồn mở, đồng thời chuyên về việc giúp các tổ chức triển khai và mở rộng quy mô các khối lượng công việc AI trên EKS.\nChristina Andonov là Kiến trúc sư Giải pháp Chuyên biệt Cấp cao tại Amazon Web Services (AWS), nơi cô hỗ trợ khách hàng triển khai các khối lượng công việc AI trên Amazon EKS bằng cách ứng dụng các công cụ mã nguồn mở. Cô có niềm đam mê đặc biệt với Kubernetes và được biết đến với khả năng truyền đạt những khái niệm phức tạp một cách dễ hiểu và trực quan.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Thực thi chính sách gắn thẻ (tagging) trên toàn tổ chức cho Amazon S3 Buckets Trong các môi trường đám mây phức tạp ngày nay, việc duy trì tính nhất quán trong resource tagging (gắn thẻ tài nguyên) là một thách thức quan trọng mà các tổ chức ở mọi quy mô đều phải đối mặt. Resource tagging đúng cách đóng vai trò thiết yếu trong phân bổ chi phí, tuân thủ bảo mật, quản lý vận hành, và duy trì quản trị ở quy mô lớn. Tuy nhiên, việc thực thi các tiêu chuẩn tagging trên các nhóm phân tán và số lượng lớn tài nguyên có thể rất khó khăn, đặc biệt khi phải xử lý chu kỳ triển khai nhanh và các yêu cầu đến từ nhiều bên liên quan khác nhau. Nhiều tổ chức thường gặp khó khăn trong việc duy trì các thực hành tagging nhất quán, dẫn đến khả năng quan sát tài nguyên kém, phân bổ chi phí không chính xác, và gặp trở ngại trong việc duy trì tuân thủ với các chính sách nội bộ.\nAWS cung cấp nhiều tính năng giúp các tổ chức triển khai và duy trì quản lý tagging hiệu quả cho Amazon S3, dịch vụ lưu trữ đám mây đóng vai trò nền tảng cho vô số tác vụ trong các trường hợp sử dụng như phát triển, phân tích dữ liệu, sao lưu, phân phối nội dung và nhiều hơn nữa. Khi các triển khai lưu trữ mở rộng và trở nên phân tán hơn giữa các nhóm và dự án, chúng thường trở thành ví dụ điển hình cho các thách thức về resource tagging. Thông qua sự kết hợp giữa các biện pháp kiểm soát chủ động và phản ứng (proactive and reactive controls), các tổ chức có thể thiết lập các cơ chế tự động để đảm bảo rằng tài nguyên đáp ứng đầy đủ các yêu cầu về tagging. Các biện pháp kiểm soát này có thể được áp dụng trên toàn bộ AWS Organization, giúp cung cấp khả năng giám sát tập trung đồng thời vẫn duy trì tính linh hoạt cần thiết cho các đơn vị kinh doanh và tác vụ khác nhau.\nTrong bài viết này, tôi sẽ minh họa cách triển khai một giải pháp quản lý tagging tự động dạng phản ứng (reactive) cho S3 buckets bằng cách sử dụng AWS Config, AWS Lambda, và Amazon EventBridge. Bạn sẽ học cách triển khai một giải pháp có khả năng tự động hạn chế việc tải lên đối tượng vào các bucket không tuân thủ, và gỡ bỏ các hạn chế này khi các tag cần thiết được áp dụng. Cách tiếp cận này cho phép các tổ chức thực thi tiêu chuẩn tagging mà không cần can thiệp thủ công, đảm bảo phân loại tài nguyên nhất quán và phân bổ chi phí chính xác — đồng thời giảm thiểu tác động đến các nhóm phát triển và quy trình làm việc hiện có.\nGiới thiệu về giải pháp Giải pháp này sử dụng cách tiếp cận phản ứng (reactive approach) trong quản lý gắn thẻ tài nguyên (tagging), dựa trên dịch vụ AWS Config với quy tắc tuân thủ có sẵn “required-tags”. Quy tắc này giám sát và xác định các tài nguyên thiếu tag cần thiết. Sau đó, quy tắc sẽ áp dụng chính sách tài nguyên cho các bucket không tuân thủ nhằm chặn việc tải lên đối tượng mới. Khi chủ sở hữu bucket thêm các tag cần thiết, giải pháp sẽ tự động gỡ bỏ chính sách, hủy bỏ hạn chế tải lên đối tượng. Với một số điều chỉnh nhỏ trong cấu hình, giải pháp này có thể được mở rộng để thực thi tagging cho các loại tài nguyên AWS khác.\nGiải pháp được triển khai theo mô hình hub-and-spoke, trong đó việc giám sát tuân thủ được thực hiện ở cấp tài khoản và AWS Region. Sau đó, các thay đổi về trạng thái tuân thủ sẽ được chuyển tiếp đến một tài khoản trung tâm, tài khoản này chịu trách nhiệm thực hiện hành động khi một S3 bucket chuyển từ trạng thái tuân thủ (compliance) sang không tuân thủ (non-compliant), hoặc ngược lại. Giải pháp này sử dụng AWS Config để đánh giá trạng thái tuân thủ và phát hiện thay đổi, EventBridge để truyền thông tin thay đổi, và Lambda để thực hiện hành động khắc phục tự động.\nSơ đồ sau minh họa các thành phần được triển khai như một phần của giải pháp này:\nHình 1: Sơ đồ kiến trúc của các tài nguyên AWS được triển khai bởi các CloudFormation template vào tài khoản quản lý và tài khoản được liên kết để hỗ trợ cho giải pháp này.\nMỗi tài khoản được triển khai giải pháp sẽ có một quy tắc AWS Config (AWS Config rule) dùng để giám sát việc tuân thủ quy định gắn thẻ (tagging compliance) của các S3 bucket. Mỗi tài khoản/Region được liên kết cũng có một EventBridge rule để chuyển tiếp thông báo về thay đổi trạng thái tuân thủ đến tài khoản quản lý giải pháp (hoặc tài khoản điều phối được chỉ định).\nTài khoản quản lý giải pháp có EventBridge bus tập trung, một rule, và một Lambda function chịu trách nhiệm cập nhật chính sách của S3 bucket dựa trên trạng thái tuân thủ tagging. Nếu bạn muốn thực thi tagging ngay trên tài khoản quản lý (hoặc tài khoản điều phối được chỉ định) đồng thời sử dụng nó để điều phối, hãy đảm bảo rằng cả hai mẫu CFN đều được triển khai trong tài khoản đó. Trong trường hợp này, tất cả các thành phần được minh họa trong hình trước đều sẽ được triển khai trong cùng tài khoản.\nGiải pháp này cũng khuyến nghị bạn sử dụng khả năng quản lý chủ động với AWS Organization tag policies (tùy chọn). Tag policies cho phép bạn đảm bảo tính nhất quán trong cách đặt tên các tag key và giới hạn các giá trị được phép gán. Các AWS CloudFormation template được cung cấp cùng với bài viết này không triển khai tag policies, vì vậy bạn cần cấu hình chúng riêng biệt.\nGiám sát: Một AWS Config rule trong mỗi tài khoản và AWS Region thuộc tổ chức của bạn sẽ giám sát các S3 bucket nhằm đảm bảo chúng tuân thủ chính sách tagging được định nghĩa trong quy tắc. Khi trạng thái tuân thủ thay đổi, quy tắc sẽ gửi một sự kiện đến Default EventBridge bus trong tài khoản đó.\nChuyển tiếp sự kiện: EventBridge rule trong từng tài khoản riêng lẻ sẽ nhận sự kiện này và chuyển tiếp nó đến custom EventBridge bus tập trung, được lưu trữ trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định).\nXử lý: Một rule được thiết lập trên custom EventBridge bus trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định) sẽ nhận sự kiện, sau đó gửi đến Lambda function để xử lý. Quy tắc này cũng ghi lại sự kiện trong Amazon CloudWatch Logs nhằm lưu trữ nhật ký.\nÁp dụng chính sách: Lambda function sẽ kiểm tra xem trạng thái tuân thủ của S3 bucket có phải là “Non-compliant” hay không, và cập nhật chính sách tài nguyên của bucket để ngăn việc tải lên bất kỳ đối tượng nào bằng chính sách tài nguyên (resource policy) sau đây:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;BlockFileUploadToBucket\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::\u0026lt;bucket name\u0026gt;/*\u0026#34; } ] } Hàm Lambda trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định) sẽ cập nhật chính sách của bucket trong tài khoản được liên kết. Quá trình này được thực hiện bằng cách giả định một vai trò được triển khai thông qua StackSets đến mỗi tài khoản mục tiêu.\nKhắc phục: Khi bucket trở lại trạng thái “Compliant”, tức là khi các tag cần thiết đã được áp dụng cho S3 bucket, Lambda function sẽ gỡ bỏ hạn chế tải lên đối tượng bằng cách xóa chính sách tài nguyên của bucket. Quy trình triển khai Để triển khai giải pháp này, hãy sử dụng hai CloudFormation template được cung cấp trong dự án GitHub kèm theo. Một template được thiết kế để triển khai trong tài khoản quản lý hoặc tài khoản được chỉ định làm tài khoản trung tâm cho giải pháp. Mẫu CFN thứ hai sẽ được triển khai trong từng tài khoản và AWS Region nơi cần thực thi quy tắc tagging. Việc triển khai này có thể được thực hiện trực tiếp bằng CloudFormation Stacks hoặc thông qua CloudFormation StackSets từ tài khoản quản lý của Organization.\nMẫu CloudFormation s3-tagging-governance-mngt.yaml triển khai các thành phần được thiết kế để chạy trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định) của bạn.\nBạn có thể triển khai mẫu này trong tài khoản quản lý của mình hoặc trong tài khoản khác đóng vai trò tài khoản điều phối được chỉ định, chịu trách nhiệm quản lý thông báo không tuân thủ và thực hiện các hành động khắc phục.\nHãy triển khai tại một Region duy nhất, nơi phần lớn tài nguyên của bạn được triển khai.\nSử dụng CloudFormation Stacks để triển khai mẫu này.\nTrong quá trình triển khai, bạn cần cung cấp OrgID của Organization. Để lấy OrgID: vào Organizations Console → Settings, mục Organization Detail sẽ hiển thị Organization ID.\nKhi quá trình triển khai hoàn tất thành công, truy cập tab Outputs của CFN Stack vừa triển khai và lưu lại các giá trị sau (bạn sẽ cần sử dụng chúng khi triển khai mẫu CFN s3-tagging-governance-linked.yaml):\na. CentralEventBusArn: chứa Amazon Resource Name (ARN) của Event Bus trung tâm đã được triển khai.\nb. LambdaAssumeRole: chứa tên của role mà Lambda sẽ assume trong quá trình thực thi để triển khai cập nhật chính sách tài nguyên trong từng tài khoản được liên kết.\nc. LambdaMngtExecutionRoleArn: chứa ARN của Lambda execution role được triển khai trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định).\nMẫu CloudFormation s3-tagging-governance-linked.yaml sẽ được triển khai vào các tài khoản và Region nơi bạn muốn thực hiện quản lý tagging.\nTriển khai bằng CloudFormation StackSets hoặc CFN Stacks thông thường.\nHãy triển khai trong từng tài khoản và AWS Region nơi bạn muốn thực thi quy tắc tagging.\nKhi triển khai mẫu này, hãy sử dụng các giá trị mà bạn đã ghi lại khi triển khai mẫu CFN s3-tagging-governance-mngt.yaml:\na. ExecLambdaRoleName: sử dụng giá trị đầu ra (output parameter) chứa tên của role mà Lambda sẽ assume trong quá trình thực thi để cập nhật chính sách tài nguyên trong từng tài khoản được liên kết.\nb. MngtEventBusArn: sử dụng giá trị đầu ra chứa ARN của Event Bus được triển khai trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định).\nc. MngtLambdaRoleArn: sử dụng giá trị đầu ra chứa ARN của Lambda execution role được triển khai trong tài khoản quản lý (hoặc tài khoản điều phối được chỉ định).\nHãy đảm bảo triển khai mẫu này trong tài khoản quản lý giải pháp (hoặc tài khoản điều phối được chỉ định) cùng với s3-tagging-governance-mngt.yaml, nếu bạn cũng muốn thực thi quy tắc tuân thủ tagging cho S3 buckets trong tài khoản đó.\nCác CloudFormation template không triển khai tag policies, tuy nhiên bạn có thể tự định nghĩa chúng bằng cách làm theo hướng dẫn tại đây: AWS Organizations – Tag Policies.\nMột vài cân nhắc quan trọng Giải pháp được đóng gói hiện tại sử dụng tag để xác định phạm vi cho AWS Config rule. Tag mà Config rule tìm kiếm có key là “TagsRequired-PLEASE-UPDATE” và value là “Yes”. Trước khi triển khai giải pháp, hãy cập nhật các CloudFormation template để đổi tag thành một tag được dùng để xác định bucket nào sẽ được quản lý bởi chính sách này, hoặc sử dụng kỹ thuật khác để định nghĩa phạm vi cho AWS Config Rule (ví dụ resource).\nLưu ý quan trọng: Khi triển khai giải pháp này, hãy cân nhắc kỹ những S3 bucket nào sẽ được nhắm mục tiêu (tham khảo bullet trước đó) và tác động của việc này đến các tác vụ hiện có đang sử dụng các bucket đó. Khi giải pháp áp dụng resource policy lên các bucket không tuân thủ, các tác vụ sẽ không còn có thể tải lên tệp vào những bucket này nữa, điều này có thể ảnh hưởng tiêu cực đến tác vụ của bạn.\nNếu S3 bucket của bạn đã có bucket resource policy, và một bucket không tuân thủ (tức là chưa có các tag cần thiết) đã có chính sách hiện có, thì chính sách này sẽ được cập nhật để bổ sung một statement nhằm chặn việc tải lên tệp, theo quy tắc của giải pháp này. Các statement hiện có của bạn sẽ không bị ảnh hưởng. Lambda function sẽ kiểm tra tất cả các statement bằng Statement ID (SID) để xác định xem statement có ID “BlockFileUploadToBucket” đã tồn tại hay chưa, và thêm vào nếu chưa có. Khi bucket trở lại trạng thái tuân thủ (Compliant), Lambda sẽ sử dụng cùng SID đó để xóa statement này khỏi policy.\nĐể ngăn người dùng tự chỉnh sửa chính sách của S3 bucket, hãy sử dụng Service Control Policies (SCPs) hoặc chính sách AWS Identity and Access Management (IAM) để giới hạn quyền của người dùng, bằng cách từ chối rõ ràng (explicit deny) các hành động như “s3:PutBucketPolicy” và “s3:DeleteBucketPolicy”.\nKhách hàng tiêu biểu: Marriott International Nhóm Cloud FinOps của Marriott International dựa vào resource tag để phục vụ cho báo cáo tài chính. Các tag này được sử dụng để xác định chủ sở hữu tài nguyên và phân bổ chi phí cho các tác vụ và đơn vị kinh doanh tương ứng. Mặc dù họ đã có chính sách yêu cầu các nhóm phải sử dụng tagging, nhưng tỷ lệ tuân thủ rất thấp, và một phần lớn chi phí bị báo cáo là không được phân loại. Để thực thi chính sách này, nhóm FinOps của Marriott đã khởi động dự án xây dựng quản lý tagging trên phần lớn các dịch vụ AWS được sử dụng trong toàn bộ hệ thống của họ.\nHọ đã thành công khi sử dụng Service Control Policies (SCPs) để chặn việc tạo bất kỳ Amazon Elastic Compute Cloud (Amazon EC2) instance hoặc Amazon Elastic Block Store (Amazon EBS) volume nào không có các tag cần thiết. Tuy nhiên, khi họ cố áp dụng cùng phương pháp này cho S3 bucket, thì nảy sinh một số thách thức. Trước hết, họ gặp phải giới hạn về kích thước ký tự như đã mô tả trước đó trong bài viết, và họ phát hiện rằng điều kiện tag (tag condition) không được hỗ trợ trong SCP policies cho Amazon S3.\nTại thời điểm đó, nhóm FinOps của Marriott đã hợp tác với AWS Technical Account Manager và Solution Architect để phát triển giải pháp được mô tả trong bài viết này. Sau khi triển khai giải pháp này trên toàn bộ Organization, họ đã giảm được 80% số lượng S3 bucket chưa được gắn tag. Nhờ đó, họ có thể báo cáo chính xác chi phí liên quan đến việc sử dụng Amazon S3 cho chủ sở hữu tài nguyên tương ứng cũng như ban lãnh đạo.\nKết luận Giải pháp này minh họa một phương pháp toàn diện để thực thi quy tắc tuân thủ gắn thẻ (tagging compliance) trên Amazon S3 Buckets, sử dụng AWS Config, Amazon EventBridge, và AWS Lambda trong mô hình hub-and-spoke. Giải pháp giám sát các S3 bucket trong toàn bộ AWS Organization, tự động hạn chế việc tải lên đối tượng vào các bucket không tuân thủ thông qua resource policies, và gỡ bỏ các hạn chế này khi các tag cần thiết được áp dụng. Các thành phần chính của giải pháp bao gồm AWS Config rules cho việc giám sát, EventBridge để định tuyến sự kiện, và Lambda functions để thực thi chính sách tự động. Tất cả những thành phần này đều có thể được triển khai thông qua các AWS CloudFormation templates được cung cấp.\nLợi ích của việc triển khai giải pháp này vượt ra ngoài phạm vi thực thi tagging. Các tổ chức có thể đạt được phân bổ chi phí và quản lý tài nguyên hiệu quả hơn thông qua việc gắn tag nhất quán, như minh chứng từ Marriott với mức giảm 80% số lượng S3 bucket chưa được gắn tag. Cách tiếp cận này khắc phục các giới hạn của SCPs, mang đến một phương pháp có khả năng mở rộng để thực thi quản lý tagging mà không gặp phải giới hạn ký tự của SCP hoặc các ràng buộc đặc thù của dịch vụ. Hơn nữa, khả năng khắc phục tự động của giải pháp giúp giảm thiểu khối lượng công việc quản trị, đồng thời đảm bảo tính tuân thủ liên tục.\nĐể bắt đầu triển khai giải pháp quản lý tagging này, hãy tải xuống các CloudFormation templates được cung cấp từ GitHub repository và làm theo hướng dẫn triển khai chi tiết. Hãy cân nhắc kỹ chiến lược lựa chọn bucket mục tiêu và các yêu cầu của tác vụ hiện có trước khi triển khai. Để có thêm hướng dẫn chuyên sâu hoặc nhu cầu tùy chỉnh, hãy tham khảo tài liệu AWS hoặc liên hệ với nhóm tài khoản AWS của bạn để đảm bảo quá trình triển khai thành công, phù hợp với các yêu cầu cụ thể của tổ chức.\nTAGS: Amazon EventBridge, Amazon Simple Storage Service (Amazon S3), AWS Cloud Storage, AWS Config, AWS Lambda\nPavel Rabinovich Pavel Rabinovich là Quản lý Tài khoản Kỹ thuật Cấp cao (Senior Technical Account Manager) tại AWS, làm việc tại Washington, D.C., với hơn 25 năm kinh nghiệm trong lĩnh vực IT và kỹ thuật phần mềm. Ông tư vấn cho các khách hàng doanh nghiệp trong ngành khách sạn, y tế và bảo hiểm về chiến lược điện toán đám mây và bảo mật. Là thành viên của AWS Security Technical Field Community, ông đặc biệt tập trung vào bảo mật danh tính và ứng dụng.\nAvinash Pala Avinash Pala là Kiến trúc sư Giải pháp Điện toán Đám mây (Cloud Solution Architect) và Kiến trúc sư Dữ liệu (Data Architect). Anh là chuyên gia được chứng nhận bởi AWS (AWS Certified).\nReema Bali Reema Bali là Giám đốc – Tài chính Doanh nghiệp trên Đám mây (Director – Enterprise FinOps) tại Marriott International, chịu trách nhiệm kết nối giữa bộ phận Kỹ thuật và Tài chính, đảm bảo chi tiêu cho điện toán đám mây được tối ưu hóa mà không ảnh hưởng đến tốc độ hay đổi mới sáng tạo. Cô là một nhà lãnh đạo IT dày dặn kinh nghiệm, với hơn 25 năm làm việc trong ngành và thành tích xuất sắc trong việc triển khai các chương trình quy mô lớn, có tác động cao, phù hợp với mục tiêu chiến lược của doanh nghiệp.\nRuby Siddiqui Ruby Siddiqui là Giám đốc Cấp cao mảng Kỹ thuật FinOps và Chiến lược Công nghệ (Senior Director of FinOps Engineering and Technology Strategy) tại Marriott International, nơi cô dẫn dắt các sáng kiến về vận hành tài chính và tối ưu hóa chi phí điện toán đám mây trên toàn doanh nghiệp. Với chuyên môn sâu về kinh tế học đám mây (cloud economics), phát triển ứng dụng, quan sát hệ thống và quản trị, cô xây dựng và triển khai các thực hành FinOps có khả năng mở rộng, giúp mang lại tính minh bạch về chi phí và giá trị kinh doanh trong môi trường đa đám mây (multi-cloud).\nSri Gudavalli Sri Gudavalli là Kiến trúc sư Giải pháp (Solutions Architect) tại AWS, nơi ông hỗ trợ các khách hàng doanh nghiệp trong hành trình di chuyển và hiện đại hóa hệ thống lên đám mây. Ông làm việc với các doanh nghiệp tại khu vực miền Đông Hoa Kỳ (US-East Region) để xây dựng các ứng dụng và dịch vụ điện toán đám mây tiên tiến trên nền tảng AWS.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Tìm hiểu kiến trúc mạng và xây dựng VPC cơ bản\nTuần 3: Học và triển khai EC2, cấu hình bảo mật và web server\nTuần 4: Xây dựng web tĩnh với S3 \u0026amp; CloudFront và làm quen với RDS\nTuần 5: Đọc hiểu tài liệu chuyên sâu AWS và hoàn thiện proposal dự án\nTuần 6: Ôn tập kiến trúc bảo mật, load balancing và disaster recovery\nTuần 7: Tìm hiểu DynamoDB, Route53 và kiến trúc chịu lỗi (Resilience)\nTuần 8: Tối ưu hiệu năng \u0026amp; chi phí\nTuần 9: Thực hành DynamoDB bằng CLI và hoàn thiện kiến trúc dự án\nTuần 10: Tinh chỉnh dữ liệu cho Cognito và thử nghiệm LocalStack\nTuần 11: Hoàn thiện data pipeline và tích hợp Cognito với database\nTuần 12: Train mô hình gợi ý Personalize và xây dựng dashboard dữ liệu\nTuần 13: Deploy website, cập nhật proposal và triển khai hạ tầng AWS\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1","tags":[],"description":"","content":"Báo cáo thu hoạch: “AWS Cloud Day Vietnam – AI Edition 2025” Tên sự kiện: Vietnam Cloud Day 2025\nNgày: 18/09/2025\nĐịa điểm: Số 2 Hải Triều, Q.1, TP. Hồ Chí Minh\nVai trò: Người tham dự\n1. Mục tiêu sự kiện Sự kiện tập trung thúc đẩy chuyển đổi số tại Việt Nam thông qua sức mạnh kết hợp giữa Điện toán đám mây và Trí tuệ nhân tạo, xoay quanh bốn định hướng chính:\nPhổ cập GenAI cho doanh nghiệp: Chuyển AI tạo sinh từ xu hướng sang ứng dụng thực tiễn, nhấn mạnh vai trò của chiến lược dữ liệu toàn diện.\nKết nối kinh doanh và CNTT: Đặc biệt trong lĩnh vực tài chính, cloud được nhìn nhận như nền tảng tạo giá trị kinh doanh.\nHiện đại hóa theo đặc thù ngành: Chia sẻ các hành trình thành công như Honda Việt Nam, Xanh SM, Masterise Group.\nTăng cường bảo mật \u0026amp; khả năng phục hồi: Khuyến khích tư duy “security by design” trong toàn bộ vòng đời ứng dụng.\n2. Diễn giả Sự kiện quy tụ danh sách đầy đủ gồm 24 diễn giả, từ các quan chức chính phủ cấp cao đến các giám đốc điều hành C-level và các chuyên gia kỹ thuật.\nTên diễn giả Chức danh Tổ chức H.E. Pham Duc Long Thứ trưởng Bộ Khoa học và Công nghệ Bộ Khoa học và Công nghệ H.E. Marc E. Knapper Đại sứ Hoa Kỳ tại Việt Nam Đại sứ quán Hoa Kỳ tại Việt Nam Jaime Valles Phó Chủ tịch, TGĐ Châu Á Thái Bình Dương \u0026amp; Nhật Bản AWS Jeff Johnson Giám đốc điều hành khu vực ASEAN AWS Dr. Jens Lottner Tổng Giám đốc (CEO) Techcombank Dieter Botha CEO TymeX Trang Phung CEO U2U Network Vu Van Đồng sáng lập \u0026amp; CEO ELSA Corp Nguyen Hoa Binh Chủ tịch Nexttech Group Gia Hieu Dinh Giám đốc Công nghệ thông tin (CIO) F88 Nguyen Hong Phuong Huy Trưởng bộ phận Hạ tầng Đám mây \u0026amp; An ninh Mạng Masterise Group Nguyen Vu Hoang Trưởng bộ phận Công nghệ VTV Digital Ha Anh Van Trưởng phòng: Bộ phận Giải pháp CNTT Honda Việt Nam Nguyen Tuan Huy Giám đốc Chuyển đổi số Mobifone Minh Hoang Giám đốc Dữ liệu (CDO) Techcom Securities Vincent Nguyen Giám đốc điều hành Nam Long Commercial Property Seunghoon Chae Tổng Giám đốc MegazoneCloud Vietnam Uy Tran Đồng sáng lập \u0026amp; COO Katalon Thai Huy Chuong Trưởng bộ phận Phát triển Ứng dụng Bảo Việt Holdings Tran Dinh Khiem Giám đốc Ngân hàng Số Techcombank Christopher Bennett Giám đốc Công nghệ (CTO) TymeX Selma Belhadjamor Chuyên gia Khoa học Dữ liệu Chính Onebyzero Ngo Manh Ha Đồng CEO, CTO TechX Corp Nguyen Thanh Binh Trưởng bộ phận DevOps Renova Cloud 3. Các điểm nhấn nội dung 3.1 Chính sách \u0026amp; lãnh đạo Chính phủ Việt Nam và Hoa Kỳ tái khẳng định cam kết hỗ trợ hạ tầng số.\nCác phiên tọa đàm nhấn mạnh yếu tố con người và văn hóa trong đổi mới doanh nghiệp.\n3.2 Ngành Tài chính – Mô hình ngân hàng mới Techcombank, Bảo Việt trình bày định hướng Ecosystem Banking.\nTechX giới thiệu nền tảng XGenAI cải thiện trải nghiệm khách hàng trong lĩnh vực tài chính.\n3.3 Hiện đại hóa đa ngành Honda Việt Nam chia sẻ lộ trình di chuyển SAP lên AWS.\nVTV Digital và Mobifone trình bày quá trình chuyển đổi số từ tầm nhìn đến vận hành.\nMasterise Group chia sẻ chiến lược di chuyển khối lượng công việc VMware sang AWS.\n3.4 Dữ liệu, AI \u0026amp; DevOps Chuyên gia dữ liệu nhấn mạnh vai trò dữ liệu chất lượng trong GenAI.\nKatalon và Renova Cloud minh họa cách GenAI tăng tốc kiểm thử và tự động hóa DevOps.\n4. Bài học chính 4.1 Định hướng tư duy Công nghệ phải phục vụ mục tiêu kinh doanh.\nKhả năng phục hồi cần được thiết kế ngay từ nền tảng.\n4.2 Kiến trúc kỹ thuật AI Tạo sinh chỉ hiệu quả khi doanh nghiệp có chiến lược dữ liệu rõ ràng.\nLộ trình hiện đại hóa linh hoạt: microservices, serverless, tái nền tảng VMware,…\n4.3 Chiến lược vận hành Trọng tâm không chỉ là “di chuyển lên cloud” mà là “vận hành đổi mới liên tục”.\nCác doanh nghiệp tài chính hướng đến Open Banking và API.\n5. Khả năng ứng dụng thực tế Kiểm toán chất lượng dữ liệu trước các dự án GenAI.\nThử nghiệm GenAI trong DevOps để cải thiện tốc độ phát triển.\nÁp dụng kinh nghiệm của Honda, Masterise vào các dự án di chuyển hệ thống.\nTích hợp bảo mật xuyên suốt vòng đời ứng dụng.\n6. Trải nghiệm cá nhân Sự kiện mang lại góc nhìn toàn diện về tương lai kinh tế số Việt Nam, kết hợp hài hòa giữa chiến lược, kỹ thuật và bài học thực tế. Các chia sẻ từ Techcombank, Honda, TechX, Masterise giúp hiểu rõ hơn cách doanh nghiệp đang triển khai Cloud và AI ở quy mô lớn. Đồng thời, các phiên kỹ thuật về GenAI trong DevOps mở ra hướng tiếp cận mới trong tự động hóa và tối ưu hóa quy trình phát triển.\nBài học rút ra:\nDữ liệu là yếu tố quyết định của GenAI.\nHiện đại hóa là hành trình dài hạn.\nBảo mật phải được đặt lên hàng đầu từ bước thiết kế.\nKết luận:\nSự kiện đã chứng minh vai trò then chốt của AWS Cloud và AI Tạo sinh trong việc định hình giai đoạn tăng trưởng tiếp theo của nền kinh tế số Việt Nam, đồng thời cung cấp lộ trình rõ ràng cho các tổ chức đang hướng tới hiện đại hóa và đổi mới bền vững.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Làm quen với tài khoản AWS và thiết lập các cấu hình cơ bản để đảm bảo quản lý chi phí, bảo mật và khả năng hỗ trợ kỹ thuật khi gặp sự cố. Bắt đầu tìm hiểu về các dịch vụ nền tảng: AWS Account, AWS Budget, IAM, AWS Support. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Tạo tài khoản AWS 08/09/2025 08/09/2025 Create a new AWS account. 3 Tạo Budget 09/09/2025 09/09/2025 COST MANAGEMENT WITH AWS BUDGETS 4 - Tìm hiểu và tạo IAM - Tạo tài khoản IAM Admin cho các tác vụ hằng ngày 09/09/2025 10/09/2025 AWS Identity and Access Management (IAM) Access Control 5 - Tìm hiểu AWS Support và gửi Support Case 10/09/2025 11/09/2025 AWS Support Kết quả đạt được tuần 1: Tạo tài khoản AWS Hiểu được cấu trúc một tài khoản AWS gồm: root user, IAM users, billing, security. Root user chỉ dùng cho tác vụ nhạy cảm (như thiết lập Billing, kích hoạt MFA, hỗ trợ tài chính). Nắm được tầm quan trọng của MFA theo nguyên tắc bảo mật của AWS (Least Privilege \u0026amp; Multi-Factor Authentication). Tạo AWS Budget Biết cách thiết lập Cost Budget để theo dõi chi phí và nhận email cảnh báo khi vượt mức. Hiểu và phân biệt khái niệm của Actual cost (chi phí thực tế) vs Forecasted cost (chi phí dự đoán đến cuối tháng) Tìm hiểu IAM và tạo IAM Admin Hiểu cấu trúc IAM: User - Group - Role - Policy. Phân biệt khái niệm của IAM User (con người/ứng dụng) và IAM Role (quyền được assume bởi service hoặc user tạm thời) Tạo một IAM Admin user thay cho root để thao tác hằng ngày. Tìm hiểu AWS Support và gửi Support Case Biết được 4 cấp độ Support: Basic, Developer, Business, Enterprise. Dưới Free Tier, chỉ có Basic Support, bao gồm: Tài liệu, forum, Trusted Advisor checks cơ bản Gửi Support Case về billing Biết cách tạo một ticket để làm quen quy trình hỗ trợ kỹ thuật. Khó khăn gặp phải Khó hiểu cấu trúc Policy JSON của IAM (Action, Resource, Effect). Cách giải quyết \u0026amp; Bài học rút ra Xem mẫu Policy trong AWS Documentation và sử dụng giao diện Visual Editor để dễ tạo IAM Policy. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu rõ các khái niệm cốt lõi về Amazon VPC để xây dựng nền tảng mạng an toàn và chuẩn best practice. Thực hành tạo VPC, Subnet, Route Table, Gateway trên AWS để nắm cơ chế hoạt động thực tế. Biết cách vẽ kiến trúc mạng bằng Draw.io Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 4 Học khái niệm về VPC - Tìm hiểu Public Cloud/Private Cloud - Phân biệt Public Subnet, Private Subnet và VPN-only Subnet - Route table, Destination/Target - Internet Gateway vs NAT Gateway 16/09/2025 17/09/2025 https://www.youtube.com/watch?v=O9Ac_vGHquM\u0026amp;list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026amp;index=25 4 Thực hành tạo VPC trên AWS 17/09/2025 17/09/2025 Amazon VPC and AWS Site-to-Site VPN Workshop 6 Vẽ kiến trúc với Draw.io 19/09/2025 19/09/2025 Hướng dẫn vẽ kiến trúc AWS trên draw.io Kết quả đạt được tuần 2: VPC và sự khác nhau giữa Public Cloud - Private Cloud Public Cloud chỉ nói về việc hạ tầng do AWS sở hữu; Private Cloud liên quan đến mạng cô lập và bảo mật theo yêu cầu doanh nghiệp. VPC trong AWS là dạng Virtual Private Cloud - private theo logic, nhưng vẫn dựa trên hạ tầng public của AWS. Phân biệt Public Subnet - Private Subnet - VPN-only Subnet Public Subnet: có Route Table trỏ ra Internet Gateway (IGW) -\u0026gt; cho phép tài nguyên trong subnet truy cập internet trực tiếp. Private Subnet: không kết nối IGW -\u0026gt; muốn ra internet phải đi qua NAT Gateway hoặc NAT Instance. VPN-only Subnet: chỉ dùng để kết nối về on-premises qua VPN Gateway, không đi internet. Route Table - Destination - Target Route Table định nghĩa đường đi của lưu lượng trong VPC. Destination: địa chỉ mạng muốn gửi traffic đến Target: cổng hoặc thành phần sẽ xử lý và chuyển tiếp traffic đến Destination.\nRoute Table cho Public Subnet Ví dụ: Route table cho Public Subnet\nDestination Target 0.0.0.0/0 igw-12345 Giải thích:\n-\u0026gt; Mọi traffic ra ngoài internet (0.0.0.0/0) phải đi qua Internet Gateway.\nRoute Table cho Private Subnet\nDestination Target 0.0.0.0/0 nat-67890 Giải thích:\n-\u0026gt; Instance trong Private Subnet muốn ra internet phải đi qua NAT Gateway (không nhận inbound).\nInternet Gateway vs NAT Gateway Thành phần Công dụng Dùng trong Internet Gateway Cho phép instance trong public subnet truy cập internet và nhận traffic vào từ internet Public subnet NAT Gateway Cho phép instance trong private subnet chỉ được outbound ra internet nhưng không nhận traffic inbound từ internet Private subnet Vẽ kiến trúc với Draw.io Biết cách diễn tả VPC, subnet, AZ, IGW, NAT Gateway, EC2 bằng icon. Hiểu tiêu chuẩn vẽ kiến trúc AWS. Sơ đồ dễ nhìn giúp truyền đạt kiến trúc rõ ràng hơn khi báo cáo hoặc trình bày. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu khái niệm Amazon EC2 và nắm được sự khác nhau giữa các loại instance. Thiết lập bảo mật mạng cơ bản bằng Security Group để đảm bảo kết nối an toàn. Thực hành triển khai EC2 trên Linux \u0026amp; Windows, kết nối qua SSH và RDP. Làm quen với việc cài đặt Web Server (LAMP/XAMPP) trên EC2 để chuẩn bị cho các bài học về kiến trúc ứng dụng. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Học khái niệm về EC2, các loại instances 22/09/2025 22/09/2025 Module 02-Lab03-04.1 - Create EC2 Instances in Subnets Thiết lập Security Group cho VPC - Cấu hình inbound/outbound phù hợp để kết nối SSH 22/09/2025 22/09/2025 Thực hành: Khởi tạo, chạy và kết nối với EC2 instance trên AWS - Các thao tác cơ bản với EC2 22/09/2025 23/09/2025 Introduction to Amazon EC2 4 Triển khai EC2 instance trên Linux: - Kết nối thông qua SSH - Cách khôi phục quyền truy cập khi mất Key Pair - Cài đặt LAMP Web Server 24/08/2025 24/08/2025 5 Triển khai EC2 instance trên Window: - Kết nối thông qua Remote Desktop Protocol (RDP) - Cài đặt XAMPP trên Windows instance 24/08/2025 25/08/2025 Kết quả đạt được tuần 3: Khái niệm và kiến trúc EC2 EC2 là dịch vụ compute theo mô hình IaaS, cho phép tạo máy ảo (instances) theo nhu cầu. Hệ sinh thái EC2 gồm: Instance Types AMI EBS Volume Key Pair Security Group Elastic IP User Data (script khởi tạo máy) Security Group - lớp tường lửa đầu tiên Security Group là stateful firewall Inbound rule: kiểm soát traffic đi vào instance Outbound rule: kiểm soát traffic đi ra ngoài Triển khai EC2 Linux Kết nối SSH Khôi phục khi mất key pair: Tạo key pair mới Dùng Puttygen để truy xuất và sao chép toàn bộ giá trị Public Key của Key Pair mới vừa tạo Dừng instance Chỉnh sửa User Data của instance, dán toàn bộ câu lệnh cloud-config, bao gồm Public Key đã sao chép, vào mục ssh-authorized-keys cho tên người dùng tương ứng (ví dụ: ec2-user). Public Key phải bắt đầu bằng chuỗi ssh-rsa Khởi động lại instance Cài đặt LAMP stack (Apache, MariaDB. PHP) Triển khai EC2 Windows Kết nối qua RDP (mstsc) Lấy password Administrator thông qua key pair Cài và cấu hình XAMPP Truy cập web server từ trình duyệt Khó khăn gặp phải Ban đầu kết nối SSH bị timeout do Security Group chưa mở đúng port Khi cài LAMP, Apache chưa chạy được do Từ phiên bản Amazon 2023 có các thay đổi từ \u0026ldquo;amazon-linux-extras\u0026rdquo; sang \u0026ldquo;distro-stream repositories\u0026rdquo; Cách giải quyết \u0026amp; Bài học rút ra Kiểm tra lại Security Group đã mở đủ và đúng cổng chưa Tắt instance khi không sử dụng để tránh phát sinh chi phí. Kiểm tra phiên bản Amazon và chạy đúng lệnh. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Hiểu và thực hành triển khai lưu trữ web tĩnh bằng Amazon S3 kết hợp CloudFront. Làm quen cách sử dụng AWS CLI thông qua VSCode để thao tác dịch vụ nhanh và chuyên nghiệp hơn. Thực hành tạo và quản lý Amazon RDS (MySQL). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Nắm kiến thức cơ bản về S3 và CloudFront 29/09/2025 29/09/2025 Thực hành: - Chuyển S3 bucket thành web tĩnh - Cấu hình truy cập cho trang web - Tạo CloudFront distribution - Thực hành với Bucket Versioning 29/09/2025 30/09/2025 with Amazon S3 3 Connect AWS với VSCode và sử dụng CLI để thao tác với dịch vụ 30/09/2025 30/09/2025 4 Thực hành: Tạo các RDS instance và thao tác với MySQL trên AWS 01/10/2025 01/10/2025 Amazon Relational Database Service (Amazon RDS) Kết quả đạt được tuần 4: Hiểu cơ bản về S3 và cơ chế static website hosting S3 là object storage, thích hợp lưu trữ web tĩnh (HTML/CSS/JS). Static Web Hosting yêu cầu bật Static website hosting và chỉ định index.html \u0026amp; error.html. S3 bucket cần cấu hình public access hoặc dùng CloudFront để phân phối nội dung an toàn hơn. Thực hành triển khai website tĩnh trên S3 Upload source web vào S3 Bật static hosting Thêm bucket policy để cho phép public read Kiểm thử truy cập bằng URL endpoint Tạo và cấu hình CloudFront Distribution Origin = S3 bucket Behavior: cache, TTL, HTTP/HTTPS Distribution domain name Invalidations khi cập nhật website CloudFront giúp:\nCải thiện tốc độ phân phối nội dung Ẩn trực tiếp S3 khỏi người dùng Hỗ trợ HTTPS qua ACM Certificate Kết nối AWS với VSCode + AWS CLI Thiết lập:\nAWS Toolkit trong VSCode Cấu hình credentials (aws configure) Thao tác S3, EC2, RDS bằng lệnh CLI Thực hành Amazon RDS (MySQL) Tạo RDS MySQL instance Cấu hình subnet group, security group Kết nối bằng MySQL Workbench Tạo database \u0026amp; chạy lệnh SQL cơ bản "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Hiểu sâu hơn về các dịch vụ AWS thông qua việc dịch blog Xác định đề tài dự án nhóm và phân chia nhiệm vụ. Học cách sử dụng AWS Pricing Calculator để ước tính chi phí dự án. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Dịch Blog 1: Building geolocation verification for iGaming and sports betting on AWS Dịch Blog 2: How to run AI model inference with GPUs on Amazon EKS Auto Mode Dịch Blog 3: Enforcing organization-wide Amazon S3 bucket-tagging policies 06/10/2025 08/10/2025 Xây dựng hệ thống xác minh vị trí địa lý cho iGaming và cá cược thể thao trên AWS\u000bCách thực thi AI model inference với GPUs trên Amazon EKS Auto Mode Thực thi chính sách gắn thẻ (tagging) trên toàn tổ chức cho Amazon S3 Buckets 3 Chốt đề tài dự án nhóm, phân chia công việc cho các thành viên 07/10/2025 07/10/2025 5 Sử dụng Pricing Calculator để tính toán chi phí (ước tính) cho dự án 09/10/2025 09/10/2025 7 Viết Proposal cho dự án 11/10/2025 13/10/2025 Kết quả đạt được tuần 5: Blog 1 - Geolocation Verification for iGaming \u0026amp; Sports Betting on AWS Các kiến thức đã nắm được:\nHiểu cách kiểm soát truy cập dựa trên vị trí địa lý bằng Route 53 Geolocation, CloudFront geo-restriction. Hiểu các rủi ro như VPN, proxy spoofing và cách giảm thiểu bằng SDK + thiết bị xác minh vị trí. Nhận thức rõ tầm quan trọng của compliance đối với các ngành yêu cầu giới hạn vùng pháp lý. Blog 2 - How to run AI model inference with GPUs on Amazon EKS Auto Mode Hiểu cơ chế EKS Auto Mode tự động provision node GPU theo nhu cầu workload (dựa vào Karpenter). EKS Auto Mode hỗ trợ GPU AMI tối ưu, auto-repair node, monitoring NMA, DCGM. Quy trình deploy mô hình AI với vLLM trên GPU node -\u0026gt; đơn giản hơn nhiều so với EKS tự quản lý. Blog 3 - Organization-wide S3 Tagging Governance Sử dụng AWS Config “required-tags” rule để kiểm soát compliance toàn tổ chức. Khi bucket non-compliant, Lambda tự động áp policy deny upload; khi compliant thì tự mở khóa trở lại. Sử dụng EventBridge forwarding từ các account con về management account. AWS Pricing Calculator Ước tính chi phí EC2, Lambda, API Gateway, RDS, CloudFront, S3. Xác định dịch vụ nào tốn chi phí cao nhất trong kiến trúc. Biết cách điều chỉnh instance type, region, storage để tối ưu hóa chi phí. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Củng cố kiến thức về Secure Architecture và các cơ chế bảo mật cốt lõi của AWS. Hiểu cơ chế hoạt động của Elastic Load Balancing và các phương pháp routing. Nắm vững các chiến lược Disaster Recovery trong AWS và phân biệt RTO/RPO. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Ôn tập: Secure Architecture - Nắm chắc kiến thức về IAM (User, Group, Policy, Role, Quyền truy cập tối thiểu) - Các loại MFA để bảo mật tài khoản - So sánh Security Group vs NACL 13/10/2025 13/10/2025 3 Học khái niệm về Elastic Load Balancing: - Application Load Balancer (ALB) - Network Load Balancer (NLB) - Open Systems Interconnections - Các loại routing của NLB và ALB - Sticky Session/Session Affinity 14/10/2025 14/10/2025 4 Tìm hiểu về Key Management Service, AWS Certificate Management và cách mã hóa, lưu key 15/10/2025 15/10/2025 5 Nắm kiến thức các loại Disaster Recovery Strategies: - Backup \u0026amp; Restore - Pilot Light - Warm Standby - Multi-Site Active-Active Phân biệt RTO và PTO 16/10/2025 16/08/2025 Kết quả đạt được tuần 6: Secure Architecture Nắm vững những điểm quan trọng:\nIAM gồm User, Group, Policy, Role; tuân thủ nguyên tắc quyền tối thiểu (Least Privilege). MFA giúp bảo vệ tài khoản với các loại như: Virtual MFA, Hardware MFA, SMS MFA. Security Group: cấp phép theo stateful firewall (tự động cho phép traffic phản hồi). NACL: stateless, áp dụng ở cấp subnet, thích hợp cho các rule deny. SG kiểm soát từng instance -\u0026gt; chi tiết hơn; NACL bảo vệ lớp subnet -\u0026gt; tổng quát hơn. Elastic Load Balancing - ALB, NLB và routing ALB hoạt động ở Layer 7, hỗ trợ HTTP/HTTPS, routing theo path, host, header, query string. NLB hoạt động ở Layer 4, tối ưu tốc độ và xử lý hàng triệu request/giây, phù hợp TCP/UDP. Model OSI giúp phân biệt vai trò của ALB (L7) và NLB (L4). Hiểu các cơ chế routing: weighted, host-based, path-based (ALB) và TCP/UDP routing (NLB). Sticky Session / Session Affinity hoạt động bằng cookies để giữ kết nối người dùng về cùng target. Tìm hiểu về KMS \u0026amp; ACM - mã hóa và quản lý khóa AWS KMS giúp tạo, lưu, và quản lý khóa mã hóa (CMK) Hỗ trợ mã hóa S3, EBS, RDS và nhiều dịch vụ khác bằng envelope encryption. Phân biệt AWS-managed keys và Customer-managed keys (CMK). AWS Certificate Manager (ACM) cung cấp chứng chỉ SSL/TLS miễn phí và tự động gia hạn. Kết hợp ACM + CloudFront/ALB để đảm bảo HTTPS end-to-end. Disaster Recovery Strategies Chiến lược Mô tả Mức độ phục hồi Backup \u0026amp; Restore Sao lưu dữ liệu và khôi phục khi sự cố Thấp Pilot Light Giữ phần lõi hệ thống hoạt động ở mức tối thiểu Trung bình Warm Standby Một phiên bản thu nhỏ chạy song song Cao Multi-Site Active-Active Nhiều site hoạt động đồng thời Rất cao RTO (Recovery Time Objective): thời gian hệ thống có thể chấp nhận downtime. RPO (Recovery Point Objective): lượng dữ liệu tối đa có thể mất trong sự cố. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Hiểu và thực hành với DynamoDB Học cách sử dụng Route 53 để host website và quản lý DNS. Nắm sâu kiến thức về kiến trúc chịu lỗi (Resilient Architecture) và các chiến lược phục hồi sau thảm họa. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Tìm hiểu về DynamoDB và các thành phần 20/10/2025 20/10/2025 Amazon DynamoDB 3 Thực hành tạo DynamoDB trên AWS Tìm hiểu cách host một website với Route53 21/10/2025 21/10/2025 4 Ôn tập: Resilient Architecture - Multi AZ, Multi Region - Disaster Recovery Strategies (Backup and Restore, Pilot Light, Warm Standby, Multi Site active active) - Health Check - Load Balancing - Các dịch vụ giúp khôi phục hệ thống nhanh chóng 22/10/2025 25/10/2025 7 Vẽ kiến trúc dự án và ước tính lưu lượng sẽ dùng cho dự án 25/10/2025 26/10/2025 Kết quả đạt được tuần 7: DynamoDB DynamoDB là cơ sở dữ liệu NoSQL key-value với khả năng scale gần như vô hạn. Thành phần chính: Partition Key / Sort Key GSI (Global Secondary Index) LSI (Local Secondary Index) Provisioned / On-Demand Capacity Hosting website với Route 53 Cách mua/gắn domain vào Route 53 Tạo Hosted Zone và Record: A, CNAME Trỏ domain về: S3 Static Website CloudFront Distribution EC2 Elastic IP Hiểu cơ chế DNS propagation và TTL Resilient Architecture Concepts Multi-AZ: Tự động chuyển đổi khi có sự cố trong một Availability Zone. Multi-Region: Giải pháp dự phòng cho các hệ thống yêu cầu uptime cực cao hoặc phân phối toàn cầu. Disaster Recovery Strategies Chiến lược Độ phức tạp Chi phí Thời gian phục hồi Backup \u0026amp; Restore Thấp Thấp Lâu nhất Pilot Light TB TB Vừa Warm Standby Cao Cao Nhanh Multi-Site Active/Active Rất cao Rất cao Gần như không downtime RTO \u0026amp; RPO:\nRTO: Thời gian tối đa hệ thống có thể downtime. RPO: Lượng dữ liệu tối đa có thể mất. Health Check: Route 53 theo dõi tình trạng endpoint -\u0026gt; failover sang site dự phòng nếu có lỗi.\nLoad Balancing: ALB/NLB giúp phân phối lưu lượng và tăng khả năng chịu lỗi.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Củng cố kiến thức về High-Performing Architectures để tối ưu hiệu năng hệ thống. Nắm chắc các kỹ thuật tối ưu chi phí Cost Optimization. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Ôn tập: High Performing Architectures - Compute Scaling - Storage Optimization - Caching - Network Optimization 27/10/2025 27/10/2025 3 Ôn tập: Cost Optimized Architecture - Budget - Saving plan - Reserved instance 28/10/2025 28/10/2025 4 Tổng hợp kiến thức, giải đề do AI tạo Giải thử đề SSA 29/10/2025 30/10/2025 6 Ôn tập và thi giữa kỳ 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: High-Performing Architectures Compute Scaling:\nPhân biệt vertical scaling và horizontal scaling. Hiểu Auto Scaling Group, scaling policies và cơ chế tăng/giảm EC2 theo tải hệ thống. Storage Optimization\nCơ chế S3 tiering (S3 Standard -\u0026gt; IA -\u0026gt; Glacier) để tối ưu tốc độ \u0026amp; chi phí. Caching\nCaching giúp giảm tải backend và tăng tốc ứng dụng. Sử dụng Amazon CloudFront, ElastiCache (Redis/Memcached) để cải thiện độ trễ. Network Optimization\nHiểu tầm quan trọng của VPC endpoints, enhanced networking và tối ưu đường đi dữ liệu. Sử dụng CloudFront để giảm độ trễ toàn cầu. Cost-Optimized Architectures AWS Budget: Thiết lập cảnh báo dựa trên mức chi tiêu hoặc dự đoán chi tiêu.\nSaving Plans\nCompute Saving Plans linh hoạt (hoạt động cho EC2, Fargate, Lambda). EC2 Instance Saving Plans chi phí thấp hơn nhưng ít linh hoạt hơn. Reserved Instance (RI)\nCam kết 1-3 năm để tiết kiệm chi phí EC2/RDS. Phù hợp workload ổn định, predictable. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Thành thạo thao tác DynamoDB bằng CLI và hiểu rõ cấu trúc bảng NoSQL. Tạo dữ liệu test bằng AI để kiểm thử hệ thống. Thống nhất kiến trúc tổng thể của dự án, lựa chọn dịch vụ AWS phù hợp và tính chi phí triển khai. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành viết CLI để tạo bảng trong DynamoDB - Dùng AI gen data test thử hệ thống 03/11/2025 03/11/2025 3 - Thảo luận và thống nhất các service dùng cho dự án, vẽ lại kiến trúc và tính toán chi phí với Price Calculator, phân chia công việc và vai trò cho từng thành viên 04/11/2025 04/11/2025 4 - Tạo mock data cho dự án, tinh chỉnh các feature cho phù hợp với AWS Personalize 05/11/2025 07/11/2025 Kết quả đạt được tuần 9: Thao tác DynamoDB bằng AWS CLI Cách tạo bảng DynamoDB bằng CLI, định nghĩa Partition Key - Sort Key. Cách sử dụng lệnh để thêm (put-item), đọc (get-item), truy vấn (query), scan dữ liệu. Hiểu rõ JSON structure và cách mapping dữ liệu NoSQL. Khó khăn gặp phải Cú pháp CLI của DynamoDB dài và dễ sai định dạng JSON. Mock data ban đầu thiếu tính logic dẫn đến sai lệch khi huấn luyện mô hình Personalize. Cách giải quyết \u0026amp; Bài học rút ra Sử dụng file JSON template để tránh khai báo thiếu hoặc sai định dạng. Điều chỉnh mock data theo pattern hành vi người dùng thực tế "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Hệ thống Hiến máu \u0026amp; Cấp cứu Đại Việt (DaiVietBlood) Thực hiện bởi: Skyline Team – Đại học FPT TP.HCM\nNgày lập: 07/12/2025\nMỤC LỤC BỐI CẢNH VÀ ĐỘNG LỰC 1.1 Tóm tắt điều hành 1.2 Tiêu chí thành công của dự án 1.3 Các giả định KIẾN TRÚC GIẢI PHÁP / SƠ ĐỒ KIẾN TRÚC 2.1 Sơ đồ kiến trúc kỹ thuật 2.2 Kế hoạch kỹ thuật 2.3 Kế hoạch dự án 2.4 Các cân nhắc về bảo mật HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO 3.1 Hoạt động và Sản phẩm bàn giao 3.2 Ngoài phạm vi dự án (Out of Scope) 3.3 Lộ trình tiến lên Production BẢNG PHÂN TÍCH CHI PHÍ AWS DỰ KIẾN ĐỘI NGŨ THỰC HIỆN NGUỒN LỰC \u0026amp; ƯỚC TÍNH CHI PHÍ NHÂN SỰ NGHIỆM THU 1. BỐI CẢNH VÀ ĐỘNG LỰC 1.1 TÓM TẮT ĐIỀU HÀNH (EXECUTIVE SUMMARY) Bối cảnh Khách hàng: Hệ thống DaiVietBlood được thiết kế để phục vụ cộng đồng, bao gồm người hiến máu tình nguyện, bệnh nhân cần máu khẩn cấp và các chuyên gia y tế tại Việt Nam. Khách hàng chính của hệ thống là người hiến máu, gia đình bệnh nhân và nhân viên y tế chịu trách nhiệm quản lý kho máu và lịch hiến. Họ cần một nền tảng tập trung, tin cậy để tối ưu hóa quy trình khớp nối giữa người hiến và người nhận, cải thiện khả năng liên lạc trong các trường hợp khẩn cấp. Trong bối cảnh chuyển đổi số y tế, DaiVietBlood cung cấp giải pháp an toàn, dễ tiếp cận nhằm giải quyết tình trạng khan hiếm máu cục bộ.\nMục tiêu Kinh doanh và Kỹ thuật: Việc di chuyển hệ thống DaiVietBlood từ môi trường cục bộ (Local/On-premise) lên AWS mang lại lợi thế vượt trội:\nVề kinh doanh: AWS cho phép ứng dụng mở rộng linh hoạt theo số lượng người dùng, giảm chi phí vận hành hạ tầng cứng và đảm bảo hiệu suất ổn định trên toàn quốc. Về kỹ thuật: AWS cung cấp độ sẵn sàng cao (High Availability) và bảo mật dữ liệu y tế. Việc áp dụng kiến trúc Serverless (AWS Lambda, API Gateway, Cognito, RDS) giúp đơn giản hóa quản lý backend, tăng tốc độ phát triển và giảm chi phí bảo trì. Hệ thống được tích hợp giám sát toàn diện (CloudWatch) và tuân thủ các tiêu chuẩn bảo mật nghiêm ngặt. Tóm tắt các Use Cases chính:\nVai trò Chức năng chính Mô tả ngắn Khách (Guest) Truy cập thông tin công khai Xem hướng dẫn hiến máu, bảng tương thích nhóm máu, bài viết giáo dục mà không cần đăng nhập. Thành viên (Member) Đăng ký/Đăng nhập, Quản lý hồ sơ Tạo tài khoản, cập nhật thông tin cá nhân và nhóm máu. Đặt lịch hiến máu Chọn thời gian và địa điểm để hiến máu. Gửi yêu cầu cấp cứu Gửi yêu cầu máu khẩn cấp, hệ thống tự động tìm người hiến phù hợp. Nhân viên (Staff) Quản lý yêu cầu \u0026amp; Kho máu Duyệt yêu cầu cấp cứu, xác nhận lịch hiến, cập nhật tồn kho máu. Quản trị viên (Admin) Quản trị hệ thống Quản lý tài khoản người dùng, cấu hình khung giờ hiến, xem báo cáo tổng quan. Tóm tắt Dịch vụ Chuyên nghiệp của Đối tác: Skyline Team sẽ cung cấp dịch vụ chuyển đổi số toàn diện, bao gồm đánh giá ứng dụng hiện tại, thiết kế kiến trúc Cloud-native, và thực hiện di chuyển (migration) hệ thống sang môi trường AWS Serverless. Chúng tôi cam kết bàn giao một hệ thống an toàn, có khả năng mở rộng, kèm theo quy trình CI/CD tự động hóa và tài liệu vận hành chi tiết.\n1.2 TIÊU CHÍ THÀNH CÔNG CỦA DỰ ÁN Chức năng: 100% chức năng cốt lõi (đăng ký, đặt lịch, yêu cầu khẩn cấp, quản trị) hoạt động ổn định trên AWS, không phát sinh lỗi hồi quy. Độ sẵn sàng: Hệ thống đạt Uptime ≥ 99.9%, đảm bảo truy cập liên tục 24/7. Hiệu năng: Thời gian phản hồi ứng dụng cải thiện ít nhất 30% so với phiên bản chạy cục bộ. Thời gian xử lý yêu cầu cấp cứu giảm 40%. Chi phí: Tối ưu hóa chi phí hạ tầng ít nhất 20% nhờ mô hình Serverless và Auto-scaling. Trải nghiệm người dùng: Tỷ lệ chấp nhận UAT đạt tối thiểu 95% cho mọi vai trò người dùng. Bảo mật: Tuân thủ đầy đủ các yêu cầu về mã hóa dữ liệu, quản lý truy cập (IAM) và bảo mật API. Vận hành: Quy trình CI/CD tự động hóa hoàn toàn với thời gian deploy \u0026lt; 10 phút. Hệ thống giám sát (Monitoring) bao phủ 100% dịch vụ quan trọng. 1.3 CÁC GIẢ ĐỊNH Giả định về Kỹ thuật \u0026amp; Kiến trúc:\nMã nguồn: Ứng dụng chạy Local hiện tại (Frontend \u0026amp; Backend) đã hoàn thiện về mặt logic chức năng. Dự án tập trung vào việc Refactoring (tái cấu trúc) để đưa lên Cloud (Serverless), không bao gồm phát triển tính năng mới. AWS Region: Toàn bộ hạ tầng được triển khai tại Singapore (ap-southeast-1) để tối ưu độ trễ cho người dùng Việt Nam. Lưu ý: Trong giai đoạn thử nghiệm, do sử dụng cấu hình VPC và tài nguyên hạn chế của gói Free Tier/Student, độ trễ có thể dao động (ước tính ~3.5s/request). Hạn mức Dịch vụ (Service Limits): Tài khoản AWS sử dụng hạn mức mặc định (Soft limits). Việc tăng hạn mức để giảm độ trễ sẽ do Khách hàng phê duyệt khi cần thiết. Tích hợp bên thứ ba: Hệ thống sử dụng API Gemini cho các tính năng AI hỗ trợ. Quyền truy cập: Nhóm Skyline được cấp quyền Admin (IAM Role) để khởi tạo tài nguyên. Giả định về Vận hành \u0026amp; Tài chính:\nTên miền: Khách hàng sở hữu tên miền (ví dụ: daivietblood.com) và quyền cấu hình DNS. Chi phí: Bảng ước tính chi phí dựa trên giả định lưu lượng khoảng 50.000 yêu cầu API/tháng. Chi phí thực tế phụ thuộc vào mức sử dụng (Pay-as-you-go). 2. KIẾN TRÚC GIẢI PHÁP / SƠ ĐỒ KIẾN TRÚC 2.1 SƠ ĐỒ KIẾN TRÚC KỸ THUẬT Hệ thống DaiVietBlood sử dụng kiến trúc Serverless-First trên AWS Cloud, ưu tiên khả năng mở rộng, bảo mật và tối ưu vận hành.\nCác thành phần chính:\nHạ tầng Mạng (VPC): Public Subnet: Chứa Internet Gateway và NAT Gateway. Private Subnet: Chứa AWS Lambda và Amazon RDS để cô lập và bảo mật dữ liệu, ngăn chặn truy cập trực tiếp từ Internet. Ứng dụng \u0026amp; Dữ liệu: Frontend: Host trên AWS Amplify, phân phối qua Amazon CloudFront (CDN) và lưu trữ assets trên S3. Authentication: Amazon Cognito quản lý định danh và cấp phát JWT token. API \u0026amp; Compute: Amazon API Gateway tiếp nhận request, chuyển đến AWS Lambda để xử lý logic nghiệp vụ. Database: Amazon RDS lưu trữ dữ liệu có cấu trúc, đặt trong Private Subnet. DevOps \u0026amp; Giám sát: CI/CD: Sử dụng AWS CodePipeline, CodeBuild, CodeDeploy để tự động hóa quy trình triển khai. Monitoring: Amazon CloudWatch thu thập logs và metrics tập trung. 2.2 KẾ HOẠCH KỸ THUẬT Quy trình triển khai kỹ thuật tuân theo phương pháp Infrastructure-as-Code (IaC):\nTự động hóa Hạ tầng: Sử dụng AWS CloudFormation để khởi tạo VPC, Lambda, RDS, API Gateway, đảm bảo tính nhất quán giữa các môi trường (Dev/Staging/Prod). Phát triển Ứng dụng: Refactor backend thành các hàm Lambda module hóa (NodeJS/Python). Các biến môi trường và thông tin nhạy cảm (DB credentials) được mã hóa an toàn. Quy trình CI/CD: Source (GitHub) -\u0026gt; Build (CodeBuild) -\u0026gt; Deploy (CloudFormation/CodeDeploy). Bao gồm bước phê duyệt thủ công (Manual Approval) trước khi deploy ra môi trường Production. Chiến lược Kiểm thử: Unit Test cho Lambda, Integration Test cho API và Load Test để đảm bảo khả năng chịu tải. 2.3 KẾ HOẠCH DỰ ÁN Dự án áp dụng mô hình Agile Scrum trong 8 tuần (4 Sprints):\nSprint 1 (Nền tảng): Thiết lập AWS Account, VPC, RDS. Sprint 2 (Backend Core): Phát triển Lambda, API Gateway, Cognito. Sprint 3 (Tích hợp): Deploy Frontend (Amplify), hoàn thiện CI/CD Pipeline. Sprint 4 (Ổn định hóa): UAT, Tối ưu hiệu năng, Bàn giao. 2.4 CÁC CÂN NHẮC VỀ BẢO MẬT Quản lý Truy cập: Sử dụng Cognito cho xác thực người dùng và IAM Role cho phân quyền dịch vụ (Least Privilege). Cô lập Mạng: Database và Lambda nằm trong Private Subnet, chỉ truy cập Internet qua NAT Gateway. Bảo vệ Dữ liệu: Mã hóa dữ liệu khi lưu trữ (At-rest) trên RDS/S3 và khi truyền tải (In-transit) qua HTTPS. Giám sát An ninh: CloudWatch Logs ghi lại toàn bộ hoạt động để phục vụ kiểm tra (audit) và phát hiện xâm nhập. 3. HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO 3.1 HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO Giai đoạn Thời gian Hoạt động chính Sản phẩm bàn giao Ước tính (Man-day) Phân tích \u0026amp; Thiết kế Tuần 1 Đánh giá hiện trạng Local, thiết kế kiến trúc Cloud, lên kế hoạch migration. Tài liệu SRS, Sơ đồ kiến trúc, Đặc tả API. 5 Phát triển Local Tuần 2-3 Xây dựng logic backend, database schema, unit test cục bộ. Prototype Backend, Database Schema. 10 Frontend \u0026amp; Tích hợp Tuần 4-5 Phát triển Frontend, tích hợp API local, chuẩn bị code để refactor. Ứng dụng hoàn chỉnh chạy Local. 10 Thiết lập Hạ tầng AWS Tuần 6 Viết script CloudFormation, khởi tạo VPC, RDS, IAM. Template IaC, Môi trường VPC an toàn. 5 Refactor \u0026amp; Deploy Backend Tuần 7-8 Chuyển đổi sang Lambda, cấu hình API Gateway, Cognito. Backend Serverless hoạt động trên AWS. 10 Deploy Frontend \u0026amp; CI/CD Tuần 9-10 Host Frontend trên Amplify, thiết lập Pipeline tự động. URL Production, CI/CD Pipeline. 10 Testing \u0026amp; Go-live Tuần 11 UAT, Kiểm thử bảo mật, Tối ưu hiệu năng. Báo cáo UAT, Báo cáo bảo mật. 5 Bàn giao \u0026amp; Đào tạo Tuần 12 Chuyển giao tài khoản, đào tạo vận hành, bàn giao tài liệu. Tài liệu hướng dẫn vận hành, Nghiệm thu. 5 3.2 NGOÀI PHẠM VI DỰ ÁN (OUT OF SCOPE) - GIAI ĐOẠN MVP Do giới hạn về thời gian và tài nguyên của giai đoạn MVP, các hạng mục sau chưa được bao gồm:\nThuật toán tìm kiếm người dùng tối ưu theo vị trí thực (Geo-location) (Hiện tại sử dụng logic đơn giản hóa). Khả năng tự động mở rộng (Auto-scaling) phức tạp cho tầng Database (Hiện tại dùng RDS cơ bản). Tối ưu hóa độ trễ chuyên sâu (Latency Optimization) cho các khu vực ngoài Singapore. Các tiêu chuẩn bảo mật nâng cao (Advanced Security Compliance) như HIPAA/PCI-DSS. 3.3 LỘ TRÌNH TIẾN LÊN PRODUCTION (PATH TO PRODUCTION) Để nâng cấp từ bản MVP hiện tại lên hệ thống Production quy mô lớn, cần thực hiện:\nChiến lược Môi trường: Tách biệt hoàn toàn môi trường Dev/Staging/Prod trên các tài khoản AWS khác nhau (Multi-account strategy). Mở rộng Database: Chuyển sang Amazon Aurora Serverless hoặc sử dụng Read Replicas để tăng khả năng chịu tải đọc/ghi. Nâng cao Giám sát: Tích hợp AWS X-Ray để truy vết (trace) request và phát hiện điểm nghẽn hiệu năng. Tăng cường Bảo mật: Triển khai AWS WAF với các tập luật chặn DDoS và bot tự động; sử dụng Amazon Inspector để quét lỗ hổng định kỳ. 4. BẢNG PHÂN TÍCH CHI PHÍ AWS DỰ KIẾN Khu vực: Asia Pacific (Singapore)\nHạng mục Dịch vụ Cấu hình ước tính Chi phí tháng (USD) Network NAT Gateway 1 NAT Gateway (Bắt buộc cho Private Subnet) + Data Processing ~$43.13 VPC Subnets, Security Groups ~$13.14 CloudFront 5GB Data Transfer (Tận dụng Free Tier) ~$3.00 Compute Lambda 1,000 requests, 512MB RAM (Free Tier) ~$0.00 API Gateway 1,000 requests ~$0.00 Database RDS db.t3.micro, 20GB Storage ~$21.74 Storage S3 5GB Storage, 200 requests ~$0.14 Hosting Amplify Build \u0026amp; Hosting, WAF enabled ~$16.77 Ops CloudWatch Logs, Metrics, Alarms ~$9.41 CI/CD CodePipeline 1 Active Pipeline ~$1.05 Tổng cộng ~$108.38 / Tháng 5. ĐỘI NGŨ THỰC HIỆN Mentor (AWS FCJ): Nguyễn Gia Hưng - Head of Solutions Architect. Quản lý Dự án (PM): Nguyễn Đức Lân - Điều phối, quản lý tiến độ, tối ưu chi phí và chiến lược UAT. Technical Lead: Nguyễn Công Minh - Phụ trách CI/CD, Infrastructure (CDK), Bảo mật và Lambda. Solution Architect: Đỗ Khang - Thiết kế kiến trúc Serverless, tích hợp AI Chatbot, Chính sách dịch vụ. Fullstack Developer: Lê Hoàng Anh - Phát triển API, UI/UX Frontend và bảo mật ứng dụng. Data Engineer: Nguyễn Quách Lam Giang - Quản trị RDS, thiết kế VPC/Subnet và giám sát CloudWatch. 6. NGUỒN LỰC \u0026amp; ƯỚC TÍNH CHI PHÍ NHÂN SỰ Phân bổ thời gian (Giờ công): Dự án huy động tổng cộng 750 giờ công chia đều cho 5 thành viên qua các giai đoạn: Nền tảng, Phát triển Core, Phân tích dữ liệu, Kiểm thử và Bàn giao.\nPhân bổ chi phí:\nNhân sự: $0 (Do sinh viên thực hiện trong khuôn khổ thực tập/đồ án, tính vào tín chỉ học thuật). Hạ tầng AWS: ~$15 (Chi phí thực tế phát sinh trong quá trình dev/test sau khi trừ Credit). Tổng chi phí dự án: Rất tối ưu, chủ yếu dựa trên nguồn lực nội bộ và hỗ trợ từ chương trình AWS FCJ. 7. NGHIỆM THU 7.1 Bàn giao Sản phẩm: Sau khi hoàn thành giai đoạn \u0026ldquo;Bàn giao\u0026rdquo;, Skyline Team sẽ gửi toàn bộ Mã nguồn, Tài liệu Kiến trúc, Tài khoản Admin và Hướng dẫn vận hành cho Khách hàng/Mentor.\n7.2 Thời gian \u0026amp; Quy trình Nghiệm thu: Khách hàng có 05 ngày làm việc để kiểm tra và thực hiện UAT. Nếu sản phẩm đáp ứng Tiêu chí thành công (Mục 1.2), Khách hàng sẽ ký xác nhận nghiệm thu.\n7.3 Xử lý Lỗi: Nếu phát sinh lỗi nghiêm trọng hoặc thiếu tính năng so với phạm vi đã cam kết, Skyline Team có trách nhiệm khắc phục và gửi lại để nghiệm thu trong thời gian sớm nhất.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.2-prerequiste/","title":"Chuẩn bị","tags":[],"description":"","content":"Yêu cầu trước khi bắt đầu Trước khi bắt đầu workshop này, hãy đảm bảo bạn có:\n1. Tài khoản AWS\nTài khoản AWS đang hoạt động với quyền Administrator Khuyến nghị: Sử dụng IAM User thay vì Root account Region: Asia Pacific (Singapore) - ap-southeast-1 2. Công cụ phát triển Local\nCông cụ Phiên bản Mục đích Node.js \u0026gt;= 18.x Chạy Lambda functions locally npm/yarn Mới nhất Quản lý packages AWS CLI \u0026gt;= 2.x Tương tác với AWS services Git Mới nhất Quản lý phiên bản 3. Yêu cầu kiến thức\nHiểu biết cơ bản về AWS services (VPC, EC2, S3) Quen thuộc với REST APIs Cơ bản Node.js/JavaScript hoặc Python Kiến thức React cơ bản Bước 1: Cấu hình AWS CLI Cài đặt AWS CLI từ Hướng dẫn cài đặt AWS CLI\nCấu hình credentials:\naws configure Nhập thông tin credentials: AWS Access Key ID: [Access Key của bạn] AWS Secret Access Key: [Secret Key của bạn] Default region name: ap-southeast-1 Default output format: json Xác minh cấu hình: aws sts get-caller-identity Bước 2: Tạo IAM User cho Workshop Vào IAM Console → Users → Create user\nThông tin user:\nUser name: workshop-admin Chọn: Provide user access to the AWS Management Console Thiết lập quyền:\nChọn: Attach policies directly Tìm và chọn: AdministratorAccess Tạo user và lưu credentials an toàn\n⚠️ Lưu ý bảo mật: Sau khi hoàn thành workshop, hãy xóa IAM user này hoặc gỡ bỏ policy AdministratorAccess.\nBước 3: Kiểm tra Service Quotas Đảm bảo tài khoản của bạn có đủ quotas cho:\nDịch vụ Tài nguyên Tối thiểu cần VPC VPCs per Region 1 VPC Subnets per VPC 4 VPC NAT Gateways per AZ 1 RDS DB Instances 1 Lambda Concurrent Executions 10 API Gateway REST APIs 1 S3 Buckets 2 Kiểm tra quotas tại: Service Quotas Console → Chọn service → View quotas\nBước 4: Chuẩn bị Source Code Clone repository mẫu: git clone https://github.com/your-repo/daivietblood-workshop.git cd daivietblood-workshop Cấu trúc project: daivietblood-workshop/ ├── frontend/ # Ứng dụng React │ ├── src/ │ └── package.json ├── backend/ # Lambda functions │ ├── functions/ │ └── package.json ├── infrastructure/ # CloudFormation templates │ └── templates/ └── README.md Cài đặt dependencies: # Frontend cd frontend \u0026amp;\u0026amp; npm install # Backend cd ../backend \u0026amp;\u0026amp; npm install Bước 5: Ước tính Chi phí Dịch vụ Cấu hình Chi phí/Ngày NAT Gateway 1 NAT Gateway ~$1.08 RDS db.t3.micro ~$0.52 Lambda Free Tier $0.00 API Gateway Free Tier $0.00 S3 \u0026lt; 5GB ~$0.01 CloudFront \u0026lt; 1GB transfer ~$0.01 Amplify Build \u0026amp; Host ~$0.50 Tổng ước tính: ~$2-3/ngày\n💡 Mẹo: Hoàn thành workshop trong 1-2 ngày và dọn dẹp tài nguyên ngay lập tức để giảm thiểu chi phí.\nChecklist trước khi bắt đầu Tài khoản AWS sẵn sàng với quyền Administrator AWS CLI đã cài đặt và cấu hình Node.js \u0026gt;= 18.x đã cài đặt Git đã cài đặt Source code đã clone Region đã đặt là ap-southeast-1 "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Tạo Amazon RDS","tags":[],"description":"","content":"Bước 1: Tạo RDS MySQL Instance Vào RDS Console → Databases → Create database\nChọn phương thức tạo database:\nStandard create Engine options:\nEngine type: MySQL Engine version: MySQL 8.0.35 (hoặc phiên bản 8.0.x mới nhất) Templates:\nFree tier (cho workshop/testing) Settings:\nDB instance identifier: daivietblood-db Master username: admin Credentials management: Self managed Master password: YourSecurePassword123! Confirm password: YourSecurePassword123! ⚠️ Quan trọng: Lưu password an toàn. Bạn sẽ cần nó để kết nối từ Lambda.\nBước 2: Cấu hình Instance Instance configuration: DB instance class: db.t3.micro (Free tier eligible) Storage type: General Purpose SSD (gp2) Allocated storage: 20 GiB Storage autoscaling: Disable (để kiểm soát chi phí) Bước 3: Kết nối Connectivity:\nCompute resource: Don\u0026rsquo;t connect to an EC2 compute resource Network type: IPv4 Virtual private cloud (VPC): daivietblood-vpc DB subnet group: daivietblood-db-subnet-group Public access: No ⚠️ Quan trọng! VPC security group: Choose existing Existing VPC security groups: daivietblood-rds-sg Availability Zone: ap-southeast-1a Database port:\nDatabase port: 3306 Bước 4: Xác thực Database Database authentication: Password authentication Bước 5: Cấu hình bổ sung Database options:\nInitial database name: daivietblood DB parameter group: default.mysql8.0 Option group: default:mysql-8-0 Backup:\nEnable automated backups: Yes Backup retention period: 7 days Backup window: No preference Encryption:\nEnable encryption: Yes (mặc định) Monitoring:\nEnable Enhanced monitoring: No (để giảm chi phí) Maintenance:\nEnable auto minor version upgrade: Yes Maintenance window: No preference Deletion protection:\nEnable deletion protection: No (cho workshop) Click Create database\nℹ️ Việc tạo RDS mất 10-15 phút. Đợi đến khi status hiển thị \u0026ldquo;Available\u0026rdquo;.\nBước 6: Lấy RDS Endpoint Sau khi RDS available:\nVào RDS Console → Databases → Click daivietblood-db\nTrong tab Connectivity \u0026amp; security, copy:\nEndpoint: daivietblood-db.xxxxxxxxxxxx.ap-southeast-1.rds.amazonaws.com Port: 3306 Lưu các giá trị này cho cấu hình Lambda:\nDB_HOST=daivietblood-db.xxxxxxxxxxxx.ap-southeast-1.rds.amazonaws.com DB_PORT=3306 DB_NAME=daivietblood DB_USER=admin DB_PASSWORD=YourSecurePassword123! Bước 7: Tạo Database Schema Vì RDS nằm trong Private Subnet, bạn cần kết nối qua bastion host hoặc sử dụng Lambda để khởi tạo schema.\nCách A: Sử dụng Lambda để khởi tạo (Khuyến nghị)\nTạo Lambda function một lần để khởi tạo database:\n// init-db.js const mysql = require(\u0026#39;mysql2/promise\u0026#39;); exports.handler = async (event) =\u0026gt; { const connection = await mysql.createConnection({ host: process.env.DB_HOST, user: process.env.DB_USER, password: process.env.DB_PASSWORD, database: process.env.DB_NAME }); // Tạo các bảng const createUsersTable = ` CREATE TABLE IF NOT EXISTS users ( id INT AUTO_INCREMENT PRIMARY KEY, email VARCHAR(255) UNIQUE NOT NULL, name VARCHAR(255) NOT NULL, blood_type ENUM(\u0026#39;A+\u0026#39;, \u0026#39;A-\u0026#39;, \u0026#39;B+\u0026#39;, \u0026#39;B-\u0026#39;, \u0026#39;AB+\u0026#39;, \u0026#39;AB-\u0026#39;, \u0026#39;O+\u0026#39;, \u0026#39;O-\u0026#39;) NOT NULL, phone VARCHAR(20), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ) `; const createDonationsTable = ` CREATE TABLE IF NOT EXISTS donations ( id INT AUTO_INCREMENT PRIMARY KEY, user_id INT NOT NULL, donation_date DATE NOT NULL, location VARCHAR(255), status ENUM(\u0026#39;scheduled\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;cancelled\u0026#39;) DEFAULT \u0026#39;scheduled\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, FOREIGN KEY (user_id) REFERENCES users(id) ) `; const createEmergencyRequestsTable = ` CREATE TABLE IF NOT EXISTS emergency_requests ( id INT AUTO_INCREMENT PRIMARY KEY, requester_name VARCHAR(255) NOT NULL, blood_type ENUM(\u0026#39;A+\u0026#39;, \u0026#39;A-\u0026#39;, \u0026#39;B+\u0026#39;, \u0026#39;B-\u0026#39;, \u0026#39;AB+\u0026#39;, \u0026#39;AB-\u0026#39;, \u0026#39;O+\u0026#39;, \u0026#39;O-\u0026#39;) NOT NULL, units_needed INT NOT NULL, hospital VARCHAR(255) NOT NULL, urgency ENUM(\u0026#39;critical\u0026#39;, \u0026#39;urgent\u0026#39;, \u0026#39;normal\u0026#39;) DEFAULT \u0026#39;normal\u0026#39;, status ENUM(\u0026#39;open\u0026#39;, \u0026#39;fulfilled\u0026#39;, \u0026#39;cancelled\u0026#39;) DEFAULT \u0026#39;open\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ) `; await connection.execute(createUsersTable); await connection.execute(createDonationsTable); await connection.execute(createEmergencyRequestsTable); await connection.end(); return { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Database initialized successfully\u0026#39; }) }; }; Checklist xác minh RDS instance đã tạo và status là \u0026ldquo;Available\u0026rdquo; RDS nằm trong Private Subnet (Public access: No) RDS Security Group chỉ cho phép truy cập từ Lambda SG Endpoint và credentials đã lưu an toàn Database ban đầu daivietblood đã tạo Database schema đã khởi tạo (các bảng đã tạo) Xử lý sự cố Vấn đề Giải pháp Không thể kết nối đến RDS Xác minh Security Group cho phép inbound từ Lambda SG Tạo RDS thất bại Kiểm tra Service Quotas cho RDS instances Connection timeout Đảm bảo Lambda cùng VPC và có NAT Gateway access "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo API Gateway","tags":[],"description":"","content":"Bước 1: Tạo REST API Vào API Gateway Console → Create API\nChọn loại API:\nREST API → Build Tạo API mới:\nProtocol: REST Create new API: New API API name: daivietblood-api Description: REST API for DaiVietBlood system Endpoint Type: Regional Click Create API\nBước 2: Tạo Resources 2.1. Tạo /users Resource\nChọn root / → Actions → Create Resource\nCấu hình:\nResource Name: users Resource Path: users Enable API Gateway CORS: ✅ Check Click Create Resource\n2.2. Tạo /emergency-requests Resource\nChọn root / → Actions → Create Resource\nCấu hình:\nResource Name: emergency-requests Resource Path: emergency-requests Enable API Gateway CORS: ✅ Check Click Create Resource\nBước 3: Tạo Methods cho /users 3.1. GET /users\nChọn /users → Actions → Create Method → GET\nIntegration setup:\nIntegration type: Lambda Function Use Lambda Proxy integration: ✅ Check Lambda Region: ap-southeast-1 Lambda Function: daivietblood-get-users Click Save → OK (để thêm permission)\n3.2. POST /users\nChọn /users → Actions → Create Method → POST\nIntegration setup:\nIntegration type: Lambda Function Use Lambda Proxy integration: ✅ Check Lambda Region: ap-southeast-1 Lambda Function: daivietblood-create-user Click Save → OK\nBước 4: Tạo Methods cho /emergency-requests 4.1. GET /emergency-requests\nChọn /emergency-requests → Actions → Create Method → GET\nIntegration setup:\nIntegration type: Lambda Function Use Lambda Proxy integration: ✅ Check Lambda Function: daivietblood-emergency-requests Click Save → OK\n4.2. POST /emergency-requests\nChọn /emergency-requests → Actions → Create Method → POST\nIntegration setup:\nIntegration type: Lambda Function Use Lambda Proxy integration: ✅ Check Lambda Function: daivietblood-emergency-requests Click Save → OK\nBước 5: Bật CORS Cho mỗi resource (/users, /emergency-requests):\nChọn resource → Actions → Enable CORS\nCấu hình:\nAccess-Control-Allow-Methods: GET, POST, OPTIONS Access-Control-Allow-Headers: Content-Type, X-Amz-Date, Authorization, X-Api-Key Access-Control-Allow-Origin: * Click Enable CORS and replace existing CORS headers\nClick Yes, replace existing values\nBước 6: Deploy API Actions → Deploy API\nDeployment stage:\nDeployment stage: [New Stage] Stage name: prod Stage description: Production stage Click Deploy\nCopy Invoke URL:\nhttps://xxxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod ℹ️ Lưu URL này. Bạn sẽ cần nó để cấu hình frontend.\nBước 7: Tóm tắt cấu trúc API Sau khi hoàn thành, cấu trúc API của bạn sẽ như sau:\ndaivietblood-api │ ├── /users │ ├── GET → daivietblood-get-users │ ├── POST → daivietblood-create-user │ └── OPTIONS (CORS) │ └── /emergency-requests ├── GET → daivietblood-emergency-requests ├── POST → daivietblood-emergency-requests └── OPTIONS (CORS) Checklist xác minh REST API đã tạo /users resource đã tạo với GET và POST methods /emergency-requests resource đã tạo với GET và POST methods CORS đã bật cho tất cả resources API đã deploy lên prod stage Invoke URL đã lưu "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo cáo thu hoạch: “AI/ML \u0026amp; Generative AI trên AWS” 1. Mục tiêu sự kiện Sự kiện nhằm cung cấp cái nhìn tổng quan về các khả năng AI/ML/GenAI trên AWS, cách tận dụng mô hình nền tảng (Foundation Models), kỹ thuật Prompt Engineering, RAG và các dịch vụ AI dựng sẵn của AWS để giải quyết các bài toán thực tế. Đồng thời, sự kiện giới thiệu Amazon Bedrock AgentCore — nền tảng mới hỗ trợ xây dựng và vận hành AI Agents ở quy mô sản xuất.\n2. Diễn giả Lâm Tuấn Kiệt – Sr DevOps Engineer, FPT Software\nDanh Hoàng Hiếu Nghị – AI Engineer, Renova Cloud\nĐinh Lê Hoàng Anh – Cloud Engineer Trainee, First Cloud AI Journey\nVăn Hoàng Kha – Community Builder\n3. Nội dung nổi bật 3.1 Generative AI trên Amazon Bedrock Foundation Models (FMs): AWS cung cấp thư viện mô hình lớn từ các nhà cung cấp như Anthropic, Meta, OpenAI… giúp người dùng nhanh chóng tùy chỉnh mô hình mà không cần tự huấn luyện.\nPrompt Engineering: Các kỹ thuật phổ biến được trình bày:\nZero-shot: mô hình chỉ nhận mô tả nhiệm vụ.\nFew-shot: cung cấp một số ví dụ để mô hình học.\nChain-of-Thought: yêu cầu mô hình trình bày suy luận từng bước.\nRAG – Retrieval Augmented Generation: Kỹ thuật cải thiện độ chính xác của GenAI bằng cách bổ sung thông tin phù hợp:\nR – Retrieval: tìm kiếm dữ liệu liên quan.\nA – Augmentation: đưa dữ liệu này vào ngữ cảnh của prompt.\nG – Generation: mô hình tạo câu trả lời có căn cứ hơn. Ứng dụng: chatbot theo ngữ cảnh, tìm kiếm doanh nghiệp, tóm tắt dữ liệu.\nAmazon Titan Embeddings: Mô hình embedding giúp chuyển văn bản thành vector phục vụ tìm kiếm tương đồng, hỗ trợ đa ngôn ngữ và tối ưu cho hệ thống RAG.\nAWS AI Services – các dịch vụ AI dựng sẵn: Rekognition, Translate, Transcribe, Textract, Comprehend, Polly, Kendra, Personalize, Lookout… giúp rút ngắn thời gian phát triển sản phẩm AI.\nDemo: Ứng dụng nhận diện khuôn mặt AMZPhoto minh họa cách tích hợp AI vào sản phẩm thực tế.\n3.2 Amazon Bedrock AgentCore – Xây dựng AI Agents ở quy mô lớn Framework mới hỗ trợ phát triển và vận hành AI agent:\nTự động hóa và mở rộng workflow tác vụ\nBộ nhớ dài hạn và quản lý phiên làm việc\nQuản lý quyền truy cập \u0026amp; danh tính\nTích hợp với Browser Tool, Code Interpreter, Memory Store\nHỗ trợ các framework phổ biến: CrewAI, LangGraph, LlamaIndex, OpenAI Agents SDK…\nQuan sát, giám sát và kiểm thử nâng cao\n4. Bài học chính Bedrock là trung tâm GenAI: Dễ dàng truy cập nhiều mô hình lớn chỉ từ một dịch vụ.\nPrompt + RAG giúp nâng độ chính xác: Ngữ cảnh phù hợp quyết định chất lượng đầu ra.\nEmbeddings cải thiện khả năng tìm kiếm: Titan Embeddings hỗ trợ truy xuất thông minh hơn.\nAI Services giảm thời gian triển khai: Không cần tự huấn luyện mô hình.\nAgentCore đơn giản hóa vận hành GenAI: Giảm độ phức tạp trong scaling, memory và monitoring.\n5. Ứng dụng vào công việc Áp dụng RAG cho các dự án GenAI yêu cầu truy xuất theo ngữ cảnh.\nSử dụng dịch vụ AI dựng sẵn để tăng tốc quá trình phát triển sản phẩm.\nTận dụng kiến thức về Prompt Engineering để cải thiện chất lượng mô hình.\nCân nhắc sử dụng AgentCore trong các dự án cần AI Agents hoạt động bền vững và có khả năng mở rộng.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hoàn thiện bộ dữ liệu dự án, bổ sung các thuộc tính cần thiết để phục vụ quá trình huấn luyện và xác thực người dùng thông qua AWS Cognito. Sử dụng LocalStack để mô phỏng AWS nhằm thử nghiệm chức năng một cách an toàn, tiết kiệm chi phí và tăng tốc phát triển. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Tiếp tục tinh chỉnh dữ liệu, bổ sung thêm các feature cho AWS Cognito 10/11/2025 12/11/2025 5 Thử nghiệm dùng LocalStack mô phỏng môi trường AWS để test các chức năng 13/11/2025 14/11/2025 Kết quả đạt được tuần 10: Thử nghiệm AWS bằng LocalStack LocalStack giúp mô phỏng môi trường AWS tại máy local mà không tốn chi phí, hỗ trợ nhiều dịch\nCài đặt và cấu hình LocalStack\nSử dụng Docker để chạy LocalStack. Cấu hình AWS CLI để trỏ tới endpoint LocalStack thay vì AWS thật. Thử nghiệm các chức năng hệ thống\nTạo bảng DynamoDB local Tạo bucket S3 thử nghiệm Kiểm thử API backend mà không cần deploy lên AWS Giảm rủi ro, tiết kiệm thời gian deploy và chi phí thử nghiệm "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tinh chỉnh bộ dữ liệu hoàn chỉnh cho dự án nhằm chuẩn hóa đầu vào cho các service backend. Tìm hiểu luồng dữ liệu từ Cognito vào database và đánh giá lựa chọn lưu trữ phù hợp (S3 vs RDS vs DynamoDB). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 3 Tinh chỉnh và tạo bộ data hoàn chỉnh cho dự án 18/11/2025 20/11/2025 6 - Hiểu cách Cognito ghi dữ liệu vào database theo thời gian thực - Cân nhắc chuyển đổi sang lưu dữ liệu trên S3 hoặc RDS 21/11/2025 21/11/2025 Kết quả đạt được tuần 9: Cognito User Pool không tự động ghi dữ liệu vào database -\u0026gt; Nhưng có thể kích hoạt dữ liệu theo thời gian thực bằng:\nPost Confirmation Trigger -\u0026gt; Lambda -\u0026gt; ghi vào DynamoDB / RDS. Pre Token Generation Trigger -\u0026gt; thêm custom claims. Sync thông tin user thông qua Cognito Identity Pool (nếu dùng). So sánh S3/DynamoDB/RDS Dịch vụ Ưu điểm Nhược điểm Phù hợp khi S3 Rẻ, lưu file/dataset lớn, backup Không truy vấn nhanh, không transactional Lưu lịch sử thao tác, log, dataset RDS SQL mạnh, truy vấn phức tạp Chi phí cao hơn Lưu thông tin quan hệ, báo cáo DynamoDB Nhanh, scale lớn, event-driven Không hỗ trợ join, schema phẳng Realtime user profiles, session data "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Triển khai mô hình gợi ý của AWS Personalize với dữ liệu thực tế của dự án. Thực hiện chuyển đổi dữ liệu giữa DynamoDB và RDS MySQL để phục vụ phân tích \u0026amp; dashboard. Hỗ trợ thống kê dữ liệu và xây dựng UI dashboard cho frontend. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Set up và train dữ liệu với Personalize 24/11/2025 24/11/2025 3 Chuyển đổi dữ liệu từ DynamoDB sang RDS MySQL 25/11/2025 25/11/2025 4 Hỗ trợ thống kê số liệu và xây dựng UI dashboard cho FE 26/11/2025 28/11/2025 Kết quả đạt được tuần 12: Set up \u0026amp; Train dữ liệu với Amazon Personalize\nImport dữ liệu qua S3. Chọn đúng recipe và train mô hình. Theo dõi training metrics. Chuyển đổi dữ liệu sang RDS MySQL\nExport dữ liệu từ SQL Server -\u0026gt; MySQL-\u0026gt; đẩy lên RDS "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/1-worklog/1.12-week13/","title":"Worklog Tuần 13","tags":[],"description":"","content":"Mục tiêu tuần 13: Hoàn thiện quá trình chạy website ở môi trường local và triển khai lên cloud. Thảo luận và chỉnh sửa lại bản proposal để phù hợp với phạm vi và kiến trúc mới của dự án. Bắt đầu cấu hình hạ tầng chính cho hệ thống trên AWS: VPC, EC2 và RDS phục vụ backend \u0026amp; database. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Set up và chạy thành công website trên local, tiến hành deploy lên cloud 01/12/2025 01/12/2025 3 Thảo luận và viết lại proposal bản mới 02/12/2025 03/12/2025 4 Cấu hình VPC, EC2 và tạo RDS Instance chứa database 03/12/2025 04/12/2025 Kết quả đạt được tuần 13: Chạy dự án trên local, mua tên miền và deploy lên cloud. Test website và sửa lỗi CSS UI. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Test API Endpoints","tags":[],"description":"","content":"Bước 1: Test từ API Gateway Console 1.1. Test GET /users\nVào API Gateway Console → Chọn daivietblood-api Chọn /users → GET Click Test Click nút Test Response mong đợi:\n{ \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;[]\u0026#34; } Bước 2: Test với cURL Thay YOUR_API_URL bằng Invoke URL thực tế của bạn.\n2.1. Tạo User (POST /users)\ncurl -X POST https://YOUR_API_URL/prod/users \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;email\u0026#34;: \u0026#34;nguyen.van.a@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Nguyen Van A\u0026#34;, \u0026#34;blood_type\u0026#34;: \u0026#34;O+\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;0901234567\u0026#34; }\u0026#39; Response mong đợi:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;email\u0026#34;: \u0026#34;nguyen.van.a@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Nguyen Van A\u0026#34;, \u0026#34;blood_type\u0026#34;: \u0026#34;O+\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;0901234567\u0026#34; } 2.2. Lấy tất cả Users (GET /users)\ncurl https://YOUR_API_URL/prod/users Response mong đợi:\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;email\u0026#34;: \u0026#34;nguyen.van.a@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Nguyen Van A\u0026#34;, \u0026#34;blood_type\u0026#34;: \u0026#34;O+\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;0901234567\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-12-09T10:00:00.000Z\u0026#34; } ] 2.3. Tạo yêu cầu cấp cứu (POST /emergency-requests)\ncurl -X POST https://YOUR_API_URL/prod/emergency-requests \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;requester_name\u0026#34;: \u0026#34;Benh vien Cho Ray\u0026#34;, \u0026#34;blood_type\u0026#34;: \u0026#34;AB-\u0026#34;, \u0026#34;units_needed\u0026#34;: 5, \u0026#34;hospital\u0026#34;: \u0026#34;Cho Ray Hospital\u0026#34;, \u0026#34;urgency\u0026#34;: \u0026#34;critical\u0026#34; }\u0026#39; Response mong đợi:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;message\u0026#34;: \u0026#34;Emergency request created\u0026#34; } 2.4. Lấy yêu cầu cấp cứu (GET /emergency-requests)\ncurl https://YOUR_API_URL/prod/emergency-requests Bước 3: Test với Postman Mở Postman Tạo Collection mới: DaiVietBlood API Thêm các requests: Tên Request Method URL Get Users GET {{baseUrl}}/users Create User POST {{baseUrl}}/users Get Emergency Requests GET {{baseUrl}}/emergency-requests Create Emergency Request POST {{baseUrl}}/emergency-requests Đặt Collection variable: baseUrl: https://YOUR_API_URL/prod Bước 4: Kiểm tra Lambda Logs Vào CloudWatch Console → Log groups\nTìm log groups:\n/aws/lambda/daivietblood-get-users /aws/lambda/daivietblood-create-user /aws/lambda/daivietblood-emergency-requests Kiểm tra log streams gần đây để xem:\nCác invocations thành công Bất kỳ errors hoặc exceptions Database connection logs Các vấn đề thường gặp \u0026amp; Giải pháp Vấn đề Nguyên nhân Giải pháp 502 Bad Gateway Lambda error Kiểm tra CloudWatch logs để xem chi tiết Timeout Lambda không thể kết nối RDS Xác minh VPC, Subnets, Security Groups CORS error CORS chưa cấu hình Bật CORS trên API Gateway 500 Internal Server Error Kết nối database thất bại Kiểm tra DB credentials trong environment variables Bước 5: Kiểm tra Performance Ghi nhận thời gian response cho mỗi API call Lần gọi đầu tiên có thể chậm (Lambda cold start) Các lần gọi tiếp theo sẽ nhanh hơn Performance mong đợi:\nEndpoint Cold Start Warm GET /users ~3-5s ~200-500ms POST /users ~3-5s ~200-500ms GET /emergency-requests ~3-5s ~200-500ms 💡 Mẹo: Lambda cold start trong VPC có thể chậm. Cân nhắc sử dụng Provisioned Concurrency cho production workloads.\nChecklist xác minh GET /users trả về mảng rỗng hoặc danh sách users POST /users tạo user mới thành công GET /emergency-requests trả về danh sách requests POST /emergency-requests tạo request mới Không có CORS errors trong browser console CloudWatch logs hiển thị invocations thành công "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.3-s3-vpc/","title":"VPC &amp; Amazon RDS","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo hạ tầng mạng (VPC) và cơ sở dữ liệu (RDS) cho hệ thống DaiVietBlood.\nTổng quan Kiến trúc Nội dung Tạo VPC Tạo Amazon RDS "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Building geolocation verification for iGaming and sports betting on AWS Blog này trình bày lý do ngành iGaming cần geolocation verification để đáp ứng yêu cầu pháp lý và ngăn chặn gian lận như VPN spoofing hoặc proxy betting. Bài viết giới thiệu các phương pháp xác minh vị trí bằng Route 53, Amazon Location Service và CloudFront, nêu rõ ưu – nhược điểm của từng kỹ thuật. Bạn sẽ biết cách chọn giải pháp phù hợp để chặn truy cập trái phép ngay tại biên, cải thiện bảo mật và tối ưu chi phí hạ tầng.\nBlog 2 - How to run AI model inference with GPUs on Amazon EKS Auto Mode Blog này giải thích cách EKS Auto Mode giúp đơn giản hóa việc vận hành GPU cho AI inference bằng cách tự động xử lý node, driver, scaling và các bản vá bảo mật. Bài viết hướng dẫn cách tạo GPU NodePool, triển khai mô hình LLM với vLLM và tận dụng Karpenter để scale tài nguyên theo nhu cầu. Bạn sẽ hiểu vì sao Auto Mode cho phép các nhóm kỹ thuật tập trung vào tối ưu mô hình AI thay vì phòng thủ vận hành Kubernetes.\nBlog 3 - Enforcing organization-wide Amazon S3 bucket-tagging policies Blog này giới thiệu cách các tổ chức tự động hóa việc kiểm soát và chuẩn hóa resource tagging cho Amazon S3 để phục vụ quản trị, phân bổ chi phí và tuân thủ bảo mật. Bài viết giải thích cách kết hợp AWS Config, EventBridge và Lambda để tự động chặn hoặc cho phép upload tùy theo trạng thái tuân thủ tag. Bạn cũng sẽ học mô hình triển khai theo kiểu hub-and-spoke cùng CloudFormation StackSets để áp dụng chính sách tag trên toàn bộ tài khoản AWS trong tổ chức.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/4-eventparticipated/4.3-event3/","title":"Sự kiện 3","tags":[],"description":"","content":"Báo cáo Sự kiện: “Data Science on AWS” 1. Mục tiêu sự kiện Sự kiện nhằm chia sẻ các dịch vụ quan trọng trên AWS phục vụ xử lý dữ liệu, bao gồm phân tích cảm xúc, phân loại bình luận, xử lý ngôn ngữ tự nhiên và xây dựng mô hình học máy.\n2. Diễn giả Văn Hoàng Kha – Cloud Solutions Architect, AWS Community Builder Bạch Doãn Vương – Cloud DevOps Engineer, AWS Community Builder 3. Nội dung nổi bật 3.1 Tổng quan các khái niệm công nghệ Sự kiện mở đầu bằng việc hệ thống hóa các khái niệm chính trong lĩnh vực trí tuệ nhân tạo:\nAI (Trí tuệ nhân tạo): Ngành nghiên cứu tạo ra hệ thống thông minh. ML (Machine Learning): Nhánh của AI cho phép máy móc học từ dữ liệu. DL (Deep Learning): Sử dụng mạng nơ-ron sâu để nhận diện mẫu dữ liệu. GenAI (Generative AI): Tập trung vào việc tạo ra nội dung mới. 3.2 AWS – Nhà cung cấp dịch vụ AI/ML toàn diện AWS cung cấp bộ dịch vụ quản lý giúp doanh nghiệp triển khai AI nhanh chóng mà không cần xây dựng hạ tầng phức tạp từ đầu, phù hợp cho cả xử lý văn bản, hình ảnh và mô hình tùy chỉnh.\n3.3 Các dịch vụ AWS được giới thiệu Amazon Comprehend (Xử lý ngôn ngữ tự nhiên – NLP) Dịch vụ được nhấn mạnh nhiều nhất nhờ khả năng xử lý văn bản mạnh mẽ đa ngôn ngữ:\nPhân tích cảm xúc (Sentiment Analysis) Tóm tắt văn bản Phân tích và phân loại email số lượng lớn Nhận diện thông tin nhạy cảm (PII Detection) Các dịch vụ xử lý ngôn ngữ khác Amazon Translate: Dịch ngôn ngữ tự động. Amazon Textract: Trích xuất thông tin từ tài liệu quét, bảng biểu, mẫu form. Amazon Transcribe: Chuyển giọng nói thành văn bản. Dịch vụ phân tích hình ảnh – Computer Vision Amazon Rekognition: Nhận diện đối tượng, khuôn mặt, kiểm duyệt nội dung trong ảnh và video. Dịch vụ nâng cao trải nghiệm người dùng Amazon Personalize: Cung cấp gợi ý cá nhân hóa dựa trên hành vi người dùng. Hạ tầng mô hình tùy chỉnh Amazon SageMaker: Cho phép lập trình viên tự xây dựng, huấn luyện và triển khai mô hình ML chuyên sâu. 4. Bài học chính AWS cung cấp đầy đủ dịch vụ phục vụ xử lý dữ liệu từ văn bản, hình ảnh đến mô hình tùy chỉnh. Amazon Comprehend là giải pháp NLP toàn diện, phù hợp cho doanh nghiệp cần phân tích phản hồi khách hàng. Personalize giúp cải thiện trải nghiệm người dùng thông qua gợi ý chính xác. SageMaker cho phép xây dựng mô hình tùy chỉnh theo nhu cầu thực tế. 5. Ứng dụng vào công việc Áp dụng Comprehend cho phân tích bình luận, phân loại nội dung hoặc phát hiện PII. Sử dụng Textract \u0026amp; Transcribe để tự động hóa xử lý tài liệu. Tích hợp Personalize để cải thiện khả năng gợi ý. Xây dựng mô hình ML tùy chỉnh bằng SageMaker khi bài toán yêu cầu độ chính xác cao hơn. Event Report: “Data Science on AWS – Overview \u0026amp; Applications” 1. Event Objectives The event aims to introduce essential AWS services for data processing, including sentiment analysis, comment classification, NLP processing, and machine learning model development.\n2. Speakers Van Hoang Kha – Cloud Solutions Architect, AWS Community Builder Bach Doan Vuong – Cloud DevOps Engineer, AWS Community Builder 3. Key Highlights 3.1 Overview of Technology Concepts The event began by systematizing core AI concepts:\nAI (Artificial Intelligence): Creation of intelligent systems. ML (Machine Learning): Allows computers to learn from data. DL (Deep Learning): Uses deep neural networks to detect complex patterns. GenAI (Generative AI): Generates new content and data. 3.2 AWS as a Complete AI/ML Provider AWS offers managed services that enable businesses to apply AI quickly without the need to build infrastructure from scratch.\n3.3 AWS Services Introduced Amazon Comprehend (NLP Service) Highlighted as the most detailed service due to advanced language capabilities:\nSentiment Analysis Text Summarization Large-scale email classification PII detection for security compliance Other Language Processing Services Amazon Translate: Automated translation Amazon Textract: Extracts data from documents and forms Amazon Transcribe: Converts speech to text Image and Vision Services Amazon Rekognition: Object detection, face recognition, content moderation Customer Experience Enhancements Amazon Personalize: Generates personalized recommendations Technical Infrastructure Amazon SageMaker: Build, train, and deploy custom ML models 4. Key Takeaways AWS offers a comprehensive suite for structured and unstructured data processing. Comprehend is powerful for sentiment analysis and classification tasks. Personalize significantly boosts user engagement through personalization. SageMaker enables deep customization for complex ML workloads. 5. Practical Applications Apply Comprehend for comment analysis and PII detection. Automate document workflows using Textract \u0026amp; Transcribe. Use Personalize to enhance recommendation systems. Build specialized ML models using SageMaker. "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Cấu hình CORS &amp; Security","tags":[],"description":"","content":"Hiểu về CORS CORS (Cross-Origin Resource Sharing) là tính năng bảo mật hạn chế các trang web gửi requests đến domain khác với domain đang phục vụ trang web.\nKhi React frontend (hosted trên Amplify) gọi API Gateway, browser kiểm tra CORS headers để xác định request có được phép hay không.\nBước 1: Cấu hình CORS Headers trong Lambda Đảm bảo tất cả Lambda functions trả về CORS headers đúng:\nconst corsHeaders = { \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39;, // Hoặc domain cụ thể \u0026#39;Access-Control-Allow-Headers\u0026#39;: \u0026#39;Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token\u0026#39;, \u0026#39;Access-Control-Allow-Methods\u0026#39;: \u0026#39;GET,POST,PUT,DELETE,OPTIONS\u0026#39; }; // Trong handler response: return { statusCode: 200, headers: corsHeaders, body: JSON.stringify(data) }; Bước 2: Cấu hình API Gateway CORS Cách 1: Sử dụng Console\nVào API Gateway Console → Chọn API của bạn Cho mỗi resource: Chọn resource → Actions → Enable CORS Cấu hình allowed origins, methods, headers Click Enable CORS and replace existing CORS headers Cách 2: Sử dụng OPTIONS Method\nTạo OPTIONS method cho mỗi resource Integration type: Mock Thêm Method Response với status 200 Thêm Integration Response với headers: Access-Control-Allow-Headers: \u0026#39;Content-Type,X-Amz-Date,Authorization,X-Api-Key\u0026#39; Access-Control-Allow-Methods: \u0026#39;GET,POST,OPTIONS\u0026#39; Access-Control-Allow-Origin: \u0026#39;*\u0026#39; Bước 3: API Gateway Security Best Practices 3.1. Bật API Key (Tùy chọn)\nVào API Gateway → API Keys → Create API Key Name: daivietblood-api-key Vào Usage Plans → Create Cấu hình throttling và quota Liên kết API Key với Usage Plan Cho mỗi method, đặt API Key Required: true 3.2. Bật Request Validation\nVào API Gateway → Models → Create Tạo model cho request body: { \u0026#34;$schema\u0026#34;: \u0026#34;http://json-schema.org/draft-04/schema#\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;CreateUserModel\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;required\u0026#34;: [\u0026#34;email\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;blood_type\u0026#34;], \u0026#34;properties\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;email\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;minLength\u0026#34;: 1 }, \u0026#34;blood_type\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;A+\u0026#34;, \u0026#34;A-\u0026#34;, \u0026#34;B+\u0026#34;, \u0026#34;B-\u0026#34;, \u0026#34;AB+\u0026#34;, \u0026#34;AB-\u0026#34;, \u0026#34;O+\u0026#34;, \u0026#34;O-\u0026#34;] }, \u0026#34;phone\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } } } Áp dụng model cho POST method: Chọn method → Method Request Request Validator: Validate body Request Body: Thêm model 3.3. Bật Throttling\nVào Stages → Chọn prod Stage Settings → Default Method Throttling Cấu hình: Rate: 100 requests/second Burst: 200 requests Bước 4: Lambda Security Best Practices 4.1. Sử dụng AWS Secrets Manager cho Credentials\nThay vì lưu DB credentials trong environment variables:\nVào Secrets Manager → Store a new secret\nSecret type: Other type of secret\nKey/value pairs:\nDB_HOST: daivietblood-db.xxxx.rds.amazonaws.com DB_USER: admin DB_PASSWORD: YourSecurePassword123! DB_NAME: daivietblood Secret name: daivietblood/db-credentials\nCập nhật Lambda để lấy secrets:\nconst { SecretsManagerClient, GetSecretValueCommand } = require(\u0026#39;@aws-sdk/client-secrets-manager\u0026#39;); const client = new SecretsManagerClient({ region: \u0026#39;ap-southeast-1\u0026#39; }); const getDbCredentials = async () =\u0026gt; { const command = new GetSecretValueCommand({ SecretId: \u0026#39;daivietblood/db-credentials\u0026#39; }); const response = await client.send(command); return JSON.parse(response.SecretString); }; Thêm IAM permission cho Lambda role: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:ap-southeast-1:*:secret:daivietblood/*\u0026#34; } 4.2. Input Validation\nLuôn validate input trong Lambda:\nconst validateUser = (body) =\u0026gt; { const errors = []; if (!body.email || !isValidEmail(body.email)) { errors.push(\u0026#39;Invalid email\u0026#39;); } if (!body.name || body.name.length \u0026lt; 1) { errors.push(\u0026#39;Name is required\u0026#39;); } const validBloodTypes = [\u0026#39;A+\u0026#39;, \u0026#39;A-\u0026#39;, \u0026#39;B+\u0026#39;, \u0026#39;B-\u0026#39;, \u0026#39;AB+\u0026#39;, \u0026#39;AB-\u0026#39;, \u0026#39;O+\u0026#39;, \u0026#39;O-\u0026#39;]; if (!validBloodTypes.includes(body.blood_type)) { errors.push(\u0026#39;Invalid blood type\u0026#39;); } return errors; }; Bước 5: Redeploy API Sau khi thay đổi:\nActions → Deploy API Chọn prod stage Click Deploy Security Checklist CORS đã cấu hình đúng Lambda trả về CORS headers đúng API Key đã bật (tùy chọn nhưng khuyến nghị) Request validation đã bật Throttling đã cấu hình DB credentials lưu trong Secrets Manager (khuyến nghị) Input validation trong Lambda functions API đã redeploy sau khi thay đổi "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.4-s3-onprem/","title":"Lambda &amp; API Gateway","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo AWS Lambda functions và expose chúng qua Amazon API Gateway để xây dựng backend serverless cho DaiVietBlood.\nTổng quan Kiến trúc API Endpoints Method Endpoint Mô tả GET /users Lấy tất cả users POST /users Tạo user mới GET /users/{id} Lấy user theo ID GET /donations Lấy tất cả donations POST /donations Tạo lịch hẹn hiến máu GET /emergency-requests Lấy yêu cầu cấp cứu POST /emergency-requests Tạo yêu cầu cấp cứu Nội dung Tạo Lambda Functions Tạo API Gateway Test API Endpoints Cấu hình CORS \u0026amp; Security "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Event 1 Tên sự kiện: AWS Cloud Day Vietnam – AI Edition 2025\nThời gian: 09:00 ngày 18-09-2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AI/ML \u0026amp; Generative AI trên AWS\nThời gian: ngày 15-11-2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: Data Science on AWS\nThời gian: 16-10-2025\nĐịa điểm: FPT University\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series#3 – Security Pillar Workshop\nThời gian: 29-11-2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: Building Agentic AI – Context Optimization with Amazon Bedrock\nThời gian: 05-12-2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/4-eventparticipated/4.4-event4/","title":"Sự kiện 4","tags":[],"description":"","content":"Bài Thu Hoạch: “AWS Cloud Mastery Series #3 – Security Pillar Workshop” 1. Mục Tiêu Sự Kiện Workshop tập trung vào Security Pillar trong AWS Well-Architected Framework, bao gồm 5 nhóm nội dung chính:\nIAM (Identity \u0026amp; Access Management)\nDetection \u0026amp; Continuous Monitoring\nInfrastructure Protection\nData Protection\nIncident Response\nNgoài ra, sự kiện giới thiệu hệ sinh thái AWS Cloud Clubs, nơi hỗ trợ sinh viên phát triển kỹ năng cloud.\n2. Diễn Giả Lê Vũ Xuân An - AWS Cloud Club Captain HCMUTE\nTrần Đức Anh - AWS Cloud Club Captain SGU\nTrần Đoàn Công Lý - AWS Cloud Club Captain PTIT\nDanh Hoàng Hiếu Nghị - AWS Cloud Club Captain HUFLIT\nHuỳnh Hoàng Long - AWS Community Builders\nĐinh Lê Hoàng Anh - AWS Community Builders\nNguyễn Tuấn Thịnh - Cloud Engineer Trainee\nNguyễn Đỗ Thành Đạt - Cloud Engineer Trainee\nVăn Hoàng Kha - Cloud Security Engineer, AWS Community Builder\nThịnh Lâm - FCJ Member\nViệt Nguyễn - FCJ Member\nMendel Grabski (Long) - Ex-Head of Security \u0026amp; DevOps, Cloud Security Solution Architect\nTrịnh Trương - Platform Engineer tại TymeX, AWS Community Builder\n3. Các Nội Dung Nổi Bật 3.1 AWS Cloud Club Xây dựng cộng đồng học cloud cho sinh viên.\nCung cấp mentorship và cơ hội networking.\nHỗ trợ học tập qua các tình huống thực tế.\n3.2 IAM – Trụ cột quan trọng Áp dụng nguyên tắc Least Privilege.\nKhông dùng root access key, hạn chế wildcard (*).\nƯu tiên AWS SSO cho multi-account.\nSử dụng SCP, Permission Boundaries và MFA (TOTP \u0026amp; FIDO2).\nSecrets Manager + quy trình xoay vòng credential.\n3.3 Detection \u0026amp; Monitoring Quan sát đa lớp: Management events, Data events, VPC Flow Logs.\nEventBridge dùng để cảnh báo và tự động hóa.\nTriển khai Detection-as-Code qua CloudTrail Lake.\n3.4 GuardDuty Phát hiện mối đe dọa dựa trên CloudTrail, VPC Flow Logs và DNS queries.\nTính năng nâng cao: Malware scan, EKS audit log, RDS anomaly detection, Lambda runtime monitoring.\nTuân thủ AWS Security Best Practices \u0026amp; CIS Benchmarks.\n3.5 Network Security Phân biệt SG (stateful) vs NACL (stateless).\nRoute 53 Resolver cho hybrid.\nAWS Network Firewall + threat intel từ GuardDuty.\n3.6 Data Protection KMS key hierarchy, IAM condition khi mã hóa dữ liệu.\nACM cho chứng chỉ TLS miễn phí.\nBắt buộc encryption khi truy cập S3, DynamoDB, RDS.\nSecrets Manager rotation.\n3.7 Incident Response Best practice: dùng temporary credentials, không public S3, tách service vào private subnet.\nQuy trình IR 5 bước: Chuẩn bị → Phát hiện → Cô lập → Khôi phục → Rút kinh nghiệm.\n4. Ứng Dụng Vào Dự Án Workshop giúp nhóm cải thiện dự án Chatbot AI qua:\nIAM chặt chẽ hơn cho backend \u0026amp; admin.\nLogging – monitoring rõ ràng để tránh misconfiguration.\nÁp dụng quy trình response để xử lý sự cố nhanh và nhất quán.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.5-policy/","title":"S3, CloudFront &amp; Amplify","tags":[],"description":"","content":"Trong phần này, bạn sẽ thiết lập Amazon S3 cho tài nguyên tĩnh, CloudFront để phân phối nội dung, và AWS Amplify để host ứng dụng React frontend.\nTổng quan Kiến trúc Phần 1: Thiết lập Amazon S3 Bước 1: Tạo S3 Bucket cho Assets Vào S3 Console → Create bucket\nGeneral configuration:\nBucket name: daivietblood-assets-{your-account-id} AWS Region: Asia Pacific (Singapore) ap-southeast-1 Object Ownership:\nACLs disabled (khuyến nghị) Block Public Access settings:\nBlock all public access: ✅ (Chúng ta sẽ dùng CloudFront) Bucket Versioning:\nEnable (khuyến nghị cho production) Default encryption:\nServer-side encryption: Enable Encryption type: Amazon S3 managed keys (SSE-S3) Click Create bucket\nBước 2: Tạo Bucket Policy cho CloudFront Sau khi tạo CloudFront distribution (Phần 2), cập nhật bucket policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::daivietblood-assets-{your-account-id}/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::{account-id}:distribution/{distribution-id}\u0026#34; } } } ] } Bước 3: Upload Assets mẫu Tạo cấu trúc folder:\n/images /blood-types /icons /banners /documents Upload các hình ảnh mẫu cho ứng dụng\nPhần 2: Thiết lập CloudFront Bước 1: Tạo CloudFront Distribution Vào CloudFront Console → Create distribution\nOrigin settings:\nOrigin domain: Chọn S3 bucket của bạn Origin path: Để trống Name: daivietblood-s3-origin Origin access: Origin access control settings (recommended) Create new OAC: Click Create control setting Name: daivietblood-oac Signing behavior: Sign requests Default cache behavior:\nViewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD Cache policy: CachingOptimized Settings:\nPrice class: Use only North America and Europe (hoặc All edge locations) Default root object: index.html Click Create distribution\nQuan trọng: Copy bucket policy được cung cấp và cập nhật S3 bucket policy\nBước 2: Lấy CloudFront Domain Sau khi distribution được deploy (mất 5-10 phút):\nCopy Distribution domain name:\nhttps://d1234567890.cloudfront.net Test truy cập asset:\nhttps://d1234567890.cloudfront.net/images/logo.png Phần 3: Thiết lập AWS Amplify Bước 1: Chuẩn bị ứng dụng React Tạo React app (nếu chưa có): npx create-react-app daivietblood-frontend cd daivietblood-frontend Cài đặt dependencies: npm install axios react-router-dom Tạo file .env: REACT_APP_API_URL=https://xxxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod REACT_APP_ASSETS_URL=https://d1234567890.cloudfront.net API service mẫu (src/services/api.js): import axios from \u0026#39;axios\u0026#39;; const API_URL = process.env.REACT_APP_API_URL; export const getUsers = async () =\u0026gt; { const response = await axios.get(`${API_URL}/users`); return response.data; }; export const createUser = async (userData) =\u0026gt; { const response = await axios.post(`${API_URL}/users`, userData); return response.data; }; export const getEmergencyRequests = async () =\u0026gt; { const response = await axios.get(`${API_URL}/emergency-requests`); return response.data; }; export const createEmergencyRequest = async (requestData) =\u0026gt; { const response = await axios.post(`${API_URL}/emergency-requests`, requestData); return response.data; }; Push lên GitHub repository Bước 2: Deploy với Amplify Vào AWS Amplify Console → Create new app\nChọn source:\nGitHub → Continue Authorize AWS Amplify truy cập GitHub của bạn Thêm repository branch:\nRepository: Chọn repository của bạn Branch: main Cấu hình build settings:\nApp name: daivietblood-frontend Build and test settings: Auto-detected cho React Build settings (amplify.yml):\nversion: 1 frontend: phases: preBuild: commands: - npm ci build: commands: - npm run build artifacts: baseDirectory: build files: - \u0026#39;**/*\u0026#39; cache: paths: - node_modules/**/* Environment variables:\nThêm REACT_APP_API_URL và REACT_APP_ASSETS_URL Click Save and deploy\nBước 3: Cấu hình Custom Domain (Tùy chọn) Vào App settings → Domain management Click Add domain Nhập tên domain của bạn Cấu hình DNS records theo hướng dẫn Phần 4: Xác minh Deployment Truy cập Amplify URL:\nhttps://main.d1234567890.amplifyapp.com Test chức năng:\nHomepage load đúng API calls hoạt động (kiểm tra Network tab) Images load từ CloudFront Không có CORS errors Checklist xác minh S3 bucket đã tạo với settings đúng CloudFront distribution đã deploy S3 bucket policy đã cập nhật cho CloudFront access Assets có thể truy cập qua CloudFront URL React app đã deploy lên Amplify Environment variables đã cấu hình Frontend có thể gọi API Gateway Images load từ CloudFront "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng Hệ thống Serverless trên AWS - DaiVietBlood Tổng quan Workshop này hướng dẫn bạn xây dựng Hệ thống Hiến máu \u0026amp; Cấp cứu Serverless (DaiVietBlood) trên AWS. Bạn sẽ học cách thiết lập và cấu hình các dịch vụ AWS cốt lõi được sử dụng trong kiến trúc dự án.\nCác dịch vụ AWS sử dụng Dịch vụ Mục đích Amazon VPC Tạo mạng riêng ảo với Public/Private Subnets NAT Gateway Cho phép tài nguyên trong Private Subnet truy cập Internet Amazon RDS Cơ sở dữ liệu MySQL cho ứng dụng AWS Lambda Xử lý logic nghiệp vụ serverless Amazon API Gateway Quản lý và expose REST APIs Amazon S3 Lưu trữ tài nguyên tĩnh (images, files) Amazon CloudFront CDN phân phối nội dung toàn cầu AWS Amplify Host ứng dụng Frontend (React) AWS CodePipeline Tự động hóa CI/CD Amazon CloudWatch Giám sát và logging Bạn sẽ học được gì Thiết kế và triển khai kiến trúc Serverless-First trên AWS Cấu hình VPC với Public/Private Subnets đảm bảo bảo mật Tạo RDS MySQL trong Private Subnet Xây dựng Lambda Functions và kết nối với API Gateway Lưu trữ và phân phối nội dung với S3 và CloudFront Deploy ứng dụng React với AWS Amplify Thiết lập CI/CD Pipeline tự động Giám sát ứng dụng với CloudWatch Yêu cầu Tài khoản AWS với quyền Administrator Kiến thức cơ bản về các dịch vụ AWS Quen thuộc với Node.js và React AWS CLI đã cài đặt và cấu hình Chi phí ước tính Workshop này sử dụng các tài nguyên nằm trong AWS Free Tier khi có thể. Chi phí ước tính khoảng ~$15-20 nếu hoàn thành trong 1-2 ngày và dọn dẹp tài nguyên ngay sau đó.\nNội dung Tổng quan Workshop Chuẩn bị VPC \u0026amp; Amazon RDS Lambda \u0026amp; API Gateway S3, CloudFront \u0026amp; Amplify CI/CD, CloudWatch \u0026amp; Dọn dẹp "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/4-eventparticipated/4.5-event5/","title":"Sự kiện 5","tags":[],"description":"","content":"Báo Cáo Thu Hoạch Sự Kiện: “Building Agentic AI – Context Optimization with Amazon Bedrock” Ngày tổ chức: 05/12/2025\nĐịa điểm: Tầng 26, Bitexco Financial Tower\n1. Mục Tiêu Sự Kiện Sự kiện tập trung trình bày cách xây dựng Agentic AI (hệ thống AI đa tác vụ, đa agent) thông qua:\nTối ưu ngữ cảnh (Context Optimization) khi xây dựng AI agent.\nỨng dụng Amazon Bedrock cho multi-agent workflows.\nGiải pháp automation trong doanh nghiệp từ Diaflow và CloudThinker.\nChia sẻ kinh nghiệm triển khai agent, thiết kế tool, xây dựng workflow\n2. Diễn Giả Nguyen Gia Hung — Head of Solutions Architect, AWS\nKien Nguyen — Solutions Architect, AWS\nViet Pham — Founder \u0026amp; CEO, Diaflow\nKha Van — Community Leader, AWS\nThang Ton — Co-Founder Henry Bui — Head of Engineering\n3. Nội Dung Nổi Bật Session 1 – Agent Core (AWS) React Agent – thực thi tuần tự từng task.\nThiết kế Tool trong Agent System.\nTối ưu đánh giá và giám sát từ ngày đầu (Eval \u0026amp; Observability).\nMulti-agent \u0026amp; Multi-session: mỗi tác vụ/phòng ban vận hành theo một luồng agent riêng, trao đổi qua supervisor agent.\nSession 2 – Diaflow Vấn đề doanh nghiệp\nTheo trình bày từ Diaflow:\n90% doanh nghiệp lãng phí ~20 giờ/tuần cho tác vụ lặp lại.\nNỗi lo chính: AI có thể làm rò rỉ dữ liệu khi xử lý.\nGiải pháp Diaflow\nDiaflow giải quyết bằng mô hình AI chạy hoàn toàn trên hạ tầng của doanh nghiệp:\nDoanh nghiệp kiểm soát hoàn toàn luồng dữ liệu thông qua MCP\nHỗ trợ tích hợp nhiều dịch vụ Google \u0026amp; AWS.\nỨng dụng Automation nội bộ:\nDatabase Automation\nXử lý tài liệu\nKnowledge base\nXây dựng internal tools/apps\nLợi ích\nProcess Efficiency: Tự động hóa được đến 80% tác vụ lặp lại.\nCost-saving: Triển khai trong vài phút, thay thế nhiều công cụ rời rạc.\nUsability: Giao diện đơn giản, ai cũng có thể tạo workflow tự động.\nKết hợp với AWS Bedrock\nKết hợp đa mô hình (multi-model).\nTối ưu bảo mật dữ liệu ở mức doanh nghiệp.\nKhả năng tối ưu chi phí theo quy mô.\nSession 3 – CloudThinker Các thách thức Cloud doanh nghiệp\nChi phí hạ tầng dễ tăng vọt (Cost Explosion). Hệ thống Cloud phức tạp, khó giám sát. Khó phản ứng nhanh khi có sự cố. Giải pháp CloudThinker\nMột nền tảng “tất cả trong một” bao gồm:\nCode Review Automation\nIncident Response Agent\nOperations \u0026amp; Optimization\nSecurity \u0026amp; Compliance Automation\nGiải pháp dựa trên multi-agent framework giúp:\nTự động hóa vận hành\nGiảm chi phí\nTối ưu hệ thống liên tục\nNâng cao khả năng phản ứng sự cố\nContext Optimization\nĐược nhấn mạnh là yếu tố quyết định hiệu suất của hệ thống agent:\nInput dành cho chatbot chỉ ~10% so với input cần cho agent system.\nQuá tải context gây giảm performance.\nKỹ thuật tối ưu context:\nPrompt Caching\nContext Compaction\nTool Consolidation (gom tool vào MCI)\nParallel Tool Calling\nCross-Region Inference\nMulti-agent Architecture\nCó Supervisor Agent điều phối.\nCác Specialist Agents xử lý tác vụ chuyên sâu.\nKiến trúc Delegation giảm độ trễ \u0026amp; chia nhỏ workload.\nThách thức \u0026amp; Kinh nghiệm triển khai\nKhó nhất là Agent Starter – xây agent đầu tiên và mô hình tool calling.\nCần thiết kế tool chuẩn ngay từ đầu.\nBắt buộc phải có hệ thống Eval \u0026amp; Observability để tránh “AI out of control”.\n4. Bài học Kiến thức từ workshop hữu ích với các dự án AI/Cloud hiện tại:\nXây dựng multi-agent system cho chatbot AI có thể phân tích, lập kế hoạch, và gọi API phức tạp.\nÁp dụng context optimization để giảm chi phí và tăng hiệu năng inference.\nỨng dụng Diaflow cho workflow automation nội bộ, đặc biệt trong trích xuất dữ liệu và RAG.\nSử dụng tư duy CloudThinker về giám sát, vận hành và phản ứng sự cố trong hệ thống AI/ML.\n5. Đánh Giá Chung Sự kiện được tổ chức chuyên nghiệp, nội dung hiện đại và sát nhu cầu doanh nghiệp.\nCác ví dụ từ Diaflow và CloudThinker giúp người tham dự hình dung rõ ràng cách triển khai agent trong thực tế.\nPhần trình bày của AWS giúp xây nền tảng agentic AI đúng kỹ thuật, tập trung vào luồng dữ liệu và thiết kế tool.\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/5-workshop/5.6-cleanup/","title":"CI/CD, CloudWatch &amp; Dọn dẹp","tags":[],"description":"","content":"Trong phần cuối này, bạn sẽ thiết lập CI/CD Pipeline, cấu hình CloudWatch monitoring, và dọn dẹp tất cả tài nguyên sau khi hoàn thành workshop.\nPhần 1: CI/CD Pipeline với CodePipeline Bước 1: Tạo CodeBuild Project Vào CodeBuild Console → Create build project\nProject configuration:\nProject name: daivietblood-backend-build Description: Build project for Lambda functions Source:\nSource provider: GitHub Repository: Chọn repository của bạn Branch: main Environment:\nEnvironment image: Managed image Operating system: Amazon Linux 2 Runtime: Standard Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0 Service role: New service role Buildspec:\nBuild specifications: Use a buildspec file Tạo file buildspec.yml trong repository: version: 0.2 phases: install: runtime-versions: nodejs: 18 commands: - echo Installing dependencies... - cd backend \u0026amp;\u0026amp; npm ci pre_build: commands: - echo Running tests... - npm test || true build: commands: - echo Building Lambda packages... - mkdir -p dist - zip -r dist/get-users.zip functions/get-users/ - zip -r dist/create-user.zip functions/create-user/ - zip -r dist/emergency-requests.zip functions/emergency-requests/ post_build: commands: - echo Updating Lambda functions... - aws lambda update-function-code --function-name daivietblood-get-users --zip-file fileb://dist/get-users.zip - aws lambda update-function-code --function-name daivietblood-create-user --zip-file fileb://dist/create-user.zip - aws lambda update-function-code --function-name daivietblood-emergency-requests --zip-file fileb://dist/emergency-requests.zip artifacts: files: - dist/**/* Click Create build project Bước 2: Tạo CodePipeline Vào CodePipeline Console → Create pipeline\nPipeline settings:\nPipeline name: daivietblood-pipeline Service role: New service role Source stage:\nSource provider: GitHub (Version 2) Connection: Tạo connection mới hoặc chọn existing Repository name: Chọn repository của bạn Branch name: main Output artifact format: CodePipeline default Build stage:\nBuild provider: AWS CodeBuild Project name: daivietblood-backend-build Deploy stage:\nSkip deploy stage (Lambda đã được update trong build stage) Click Create pipeline\nBước 3: Thêm IAM Permissions cho CodeBuild Vào IAM Console → Roles Tìm role codebuild-daivietblood-backend-build-service-role Thêm inline policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:UpdateFunctionCode\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:*:function:daivietblood-*\u0026#34; } ] } Phần 2: CloudWatch Monitoring Bước 1: Tạo CloudWatch Dashboard Vào CloudWatch Console → Dashboards → Create dashboard\nDashboard name: DaiVietBlood-Monitoring\nThêm widgets:\nWidget 1: Lambda Invocations\nWidget type: Line Metrics: Lambda → By Function Name → Invocations Chọn tất cả daivietblood functions Widget 2: Lambda Errors\nWidget type: Number Metrics: Lambda → By Function Name → Errors Statistic: Sum Widget 3: Lambda Duration\nWidget type: Line Metrics: Lambda → By Function Name → Duration Statistic: Average Widget 4: API Gateway Requests\nWidget type: Line Metrics: ApiGateway → By Api Name → Count Widget 5: RDS Connections\nWidget type: Line Metrics: RDS → Per-Database Metrics → DatabaseConnections Bước 2: Tạo CloudWatch Alarms Alarm 1: Lambda Errors\nVào CloudWatch → Alarms → Create alarm Select metric: Lambda → By Function Name → Errors Conditions: Threshold type: Static Whenever Errors is: Greater than 5 Period: 5 minutes Notification: Create new SNS topic: daivietblood-alerts Email: your-email@example.com Alarm name: DaiVietBlood-Lambda-Errors Alarm 2: RDS CPU High\nCreate alarm Select metric: RDS → Per-Database Metrics → CPUUtilization Conditions: Threshold: Greater than 80% Period: 5 minutes Notification: Use existing SNS topic Alarm name: DaiVietBlood-RDS-CPU-High Alarm 3: API Gateway 5XX Errors\nCreate alarm Select metric: ApiGateway → By Api Name → 5XXError Conditions: Threshold: Greater than 10 Period: 5 minutes Alarm name: DaiVietBlood-API-5XX-Errors Bước 3: Cấu hình Log Insights Vào CloudWatch → Logs → Logs Insights\nChọn log groups:\n/aws/lambda/daivietblood-get-users /aws/lambda/daivietblood-create-user /aws/lambda/daivietblood-emergency-requests Query mẫu - Tìm errors:\nfields @timestamp, @message | filter @message like /ERROR/ | sort @timestamp desc | limit 50 Query mẫu - Thống kê duration: fields @timestamp, @duration | stats avg(@duration), max(@duration), min(@duration) by bin(1h) Phần 3: Dọn dẹp Tài nguyên ⚠️ Quan trọng: Thực hiện các bước sau để tránh phát sinh chi phí không mong muốn.\nThứ tự dọn dẹp (Quan trọng!) Dọn dẹp theo thứ tự sau để tránh dependency errors:\nBước 1: Xóa Amplify App Vào Amplify Console Chọn daivietblood-frontend Actions → Delete app Xác nhận xóa Bước 2: Xóa CloudFront Distribution Vào CloudFront Console Chọn distribution → Disable Đợi status chuyển sang \u0026ldquo;Deployed\u0026rdquo; Chọn distribution → Delete Bước 3: Xóa S3 Buckets Vào S3 Console Chọn bucket daivietblood-assets-* Empty bucket trước Sau đó Delete bucket Bước 4: Xóa API Gateway Vào API Gateway Console Chọn daivietblood-api Actions → Delete Bước 5: Xóa Lambda Functions Vào Lambda Console Xóa từng function: daivietblood-get-users daivietblood-create-user daivietblood-emergency-requests Xóa Lambda Layer: mysql2-layer Bước 6: Xóa RDS Instance Vào RDS Console → Databases Chọn daivietblood-db Actions → Delete Bỏ chọn \u0026ldquo;Create final snapshot\u0026rdquo; Chọn \u0026ldquo;I acknowledge\u0026hellip;\u0026rdquo; Nhập delete me để xác nhận Bước 7: Xóa VPC Resources Vào VPC Console\nXóa NAT Gateway:\nNAT Gateways → Chọn NAT Gateway → Delete Đợi status \u0026ldquo;Deleted\u0026rdquo; Release Elastic IP:\nElastic IPs → Chọn EIP → Release Xóa VPC Endpoints (nếu có):\nEndpoints → Chọn endpoints → Delete Xóa Security Groups (trừ default):\nSecurity Groups → Xóa daivietblood-lambda-sg, daivietblood-rds-sg Xóa DB Subnet Group:\nRDS Console → Subnet groups → Delete daivietblood-db-subnet-group Xóa VPC:\nYour VPCs → Chọn daivietblood-vpc → Delete VPC Điều này sẽ xóa subnets, route tables, internet gateway Bước 8: Xóa CI/CD Resources CodePipeline Console → Delete daivietblood-pipeline CodeBuild Console → Delete daivietblood-backend-build Bước 9: Xóa CloudWatch Resources CloudWatch → Dashboards → Delete DaiVietBlood-Monitoring CloudWatch → Alarms → Delete tất cả alarms liên quan CloudWatch → Log groups → Delete các log groups /aws/lambda/daivietblood-* Bước 10: Xóa IAM Resources IAM Console → Roles Xóa các roles: daivietblood-lambda-role codebuild-daivietblood-* codepipeline-daivietblood-* Checklist Dọn dẹp Amplify app đã xóa CloudFront distribution đã xóa S3 buckets đã empty và xóa API Gateway đã xóa Lambda functions và layers đã xóa RDS instance đã xóa NAT Gateway đã xóa Elastic IP đã release VPC và tất cả components đã xóa CodePipeline và CodeBuild đã xóa CloudWatch dashboards, alarms, log groups đã xóa IAM roles đã xóa Xác minh không còn chi phí Vào AWS Cost Explorer Kiểm tra không có tài nguyên nào đang chạy Vào Billing Console → Bills để xác nhận 💡 Mẹo: Đặt Budget Alert trong AWS Budgets để nhận thông báo khi chi phí vượt ngưỡng.\nKết luận Workshop Chúc mừng! 🎉 Bạn đã hoàn thành workshop xây dựng hệ thống Serverless trên AWS.\nNhững gì bạn đã học: ✅ Thiết kế và triển khai VPC với Public/Private Subnets ✅ Tạo RDS MySQL trong môi trường bảo mật ✅ Xây dựng Lambda functions và expose qua API Gateway ✅ Cấu hình S3 và CloudFront cho static assets ✅ Deploy React app với AWS Amplify ✅ Thiết lập CI/CD Pipeline tự động ✅ Giám sát ứng dụng với CloudWatch Bước tiếp theo: Tìm hiểu thêm về AWS Well-Architected Framework Khám phá các tính năng nâng cao như X-Ray tracing Thử nghiệm với Aurora Serverless cho database Implement authentication với Amazon Cognito "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại First Cloud Journey (FCJ) - AWS Study Group từ ngày 8 tháng 9 năm 2025 đến ngày 9 tháng 12 năm 2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia xây dựng website hỗ trợ hiến máu theo nhóm, qua đó tôi đã được làm quen với nhiều bạn mới, học thêm kiến thức về cloud và phát triển kĩ năng mềm cho bản thân.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ☐ ✅ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỷ luật, sắp xếp công việc cần làm một cách khoa học và phù hợp hơn. Học cách giao tiếp tốt hơn trong giao tiếp công việc, kết nối với nhiều bạn bè và đồng nghiệp hơn "},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các anh mentor và các thành viên FCJ luôn hỗ trợ mình kịp thời và tận tình. Mọi người hòa đồng và thân thiện, chỉ ra lỗi sai và giúp mình sửa đổi.\n2. Sự hỗ trợ của mentor / team admin\nSự hướng dẫn và hợp tác nhóm trong suốt chương trình rất xuất sắc. Team luôn sẵn sàng thảo luận các thách thức kỹ thuật, xem xét đề xuất của tôi và hướng dẫn qua các khái niệm AWS phức tạp. Điều tôi đánh giá cao nhất là mentor luôn khuyến khích tôi tự nghiên cứu và đề xuất hướng giải quyết trước khi hỗ trợ.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nTham gia FCJ giúp mình được học thêm các kĩ năng và dịch vụ mới về Cloud, những kĩ năng đó giúp cho mình có thêm hiểu biết về cách ngành khác nhau. Là một phần kĩ năng mềm giúp cho công việc sau này.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như quản lý dự án, sắp xếp và phân bố công việc, kỷ luật bản thân và giao tiếp tốt hơn trong môi trường làm việc.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất vui vẻ, dù mới lần đầu gặp gỡ các anh chị FCJ nhưng mọi người rất hòa đồng và cởi mở, giúp em không cảm thấy xa lạ. Mọi người trong lúc làm việc rất nghiêm túc nhưng khi giải lao thì rất dễ thương.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nThời gian làm việc thoải mái, không gò bó, môi trường tích cực và mọi người thân thiện cũng như hỗ trợ mình nhiệt tình khi cần sự giúp đỡ.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nCó thêm nhiều sự kiện để các thành viên có cơ hội kết nối với nhau nhiều hơn.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nRất nên thực tập ở FCJ vì môi trường năng động, hòa đồng và là cơ hội lớn để phát triển kĩ năng cá nhân\n"},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://bbitmi.github.io/fcj-internship-report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]